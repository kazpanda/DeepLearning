G検定模擬試験

テスト開始

-------

問1

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークは高い表現力を持つ反面,過学習をしやすいという性質を持つため,それを改善させる方法が多数考案されている.例えば,学習の際に一部のノードを無効化する（ア）,一部の層の出力を正規化する（イ）,データの水増しをしてデータの不足を補う（ウ）,パラメータのノルムにペナルティを課す（エ）などがそれに当たる.

1. バッチ正規化
1. ドロップアウト
1. データ拡張
1. L2正則化

正解：2


【解説】  
正解は2である.

バッチ正規化　…　一部の層の出力を正規化する.
ドロップアウト　…　学習の際に一部のノードを無効化する.
データ拡張　…　データの水増しをしてデータの不足を補う.
L2正則化　…　パラメータのノルムにペナルティを課す.

-------

問2

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークは高い表現力を持つ反面,過学習をしやすいという性質を持つため,それを改善させる方法が多数考案されている.例えば,学習の際に一部のノードを無効化する（ア）,一部の層の出力を正規化する（イ）,データの水増しをしてデータの不足を補う（ウ）,パラメータのノルムにペナルティを課す（エ）などがそれに当たる.

1. バッチ正規化
1. ドロップアウト
1. データ拡張
1. L2正則化

正解：1

【解説】  
正解は1である.

-------

問3

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークは高い表現力を持つ反面,過学習をしやすいという性質を持つため,それを改善させる方法が多数考案されている.例えば,学習の際に一部のノードを無効化する（ア）,一部の層の出力を正規化する（イ）,データの水増しをしてデータの不足を補う（ウ）,パラメータのノルムにペナルティを課す（エ）などがそれに当たる.

1. バッチ正規化
1. ドロップアウト
1. データ拡張
1. L2正則化

正解：3

【解説】  
正解は3である.

-------

問4

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークは高い表現力を持つ反面,過学習をしやすいという性質を持つため,それを改善させる方法が多数考案されている.例えば,学習の際に一部のノードを無効化する（ア）,一部の層の出力を正規化する（イ）,データの水増しをしてデータの不足を補う（ウ）,パラメータのノルムにペナルティを課す（エ）などがそれに当たる.

1. バッチ正規化
1. ドロップアウト
1. データ拡張
1. L2正則化

正解：4

【解説】  
正解は4である.

バッチ正規化　…　一部の層の出力を正規化する.
ドロップアウト　…　学習の際に一部のノードを無効化する.
データ拡張　…　データの水増しをしてデータの不足を補う.
L2正則化　…　パラメータのノルムにペナルティを課す.

-------

問5

（ア）～（ウ）に最もよくあてはまる組み合わせを 1 つ選べ.

学習率の値は学習の進み方に大きな影響を与える.例えば,学習率が過度に（ア）いとコスト関数の高い局所的最適解から抜け出せなくなることがある.また,大域的最適解に向かって収束している場合でも,学習率が（イ）いと,収束は速いがコスト関数の最終的な値が高く,逆に（ウ）くすると収束は遅いが最終的にはより最適解に近いパラメータになるため,コスト関数は小さな値に収束する.

1. 大き・小さ・小さ
1. 小さ・大き・小さ
1. 大き・小さ・大き
1. 小さ・大き・大き

正解：2

【解説】  
正解は2である.

-------

問6

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

学習率の値は学習の進み方に大きな影響を与える.例えば,学習率が過度に（ア）とコスト関数の高い局所的最適解から抜け出せなくなることがある.また,大域的最適解に向かって収束している場合でも,学習率が（イ）と,収束は速いがコスト関数の最終的な値が高く,逆に（ウ）と収束は遅いが最終的にはより最適解に近いパラメータになるため,コスト関数は小さな値に収束する.

1. 大きい
1. 小さい

正解：1

【解説】  
正解は1である.

-------

問7

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

学習率の値は学習の進み方に大きな影響を与える.例えば,学習率が過度に（ア）とコスト関数の高い局所的最適解から抜け出せなくなることがある.また,大域的最適解に向かって収束している場合でも,学習率が（イ）と,収束は速いがコスト関数の最終的な値が高く,逆に（ウ）と収束は遅いが最終的にはより最適解に近いパラメータになるため,コスト関数は小さな値に収束する.

1. 大きくする
1. 小さくする

正解：2

【解説】  
正解は2である.
学習率が小さいと,収束に時間がかかり,コスト関数の最終的な値は小さくなる.また,局所的最適解から抜け出せずそのまま収束してしまうことがある.
反対に学習率が大きい場合は,収束するのが早くなるが,コスト関数は大きな値になりやすい.

-------

問8

生成モデル（generative model）の一つであり,生成ネットワークと識別ネットワークの 2 つのネットワークを対抗させるように学習させることで,得られる生成モデル（generative model）の名称として最も適切なものを 1 つ選べ.

1. ResNet
1. VGG16
1. VAE
1. GAN

正解：4

【解説】  
正解は4である.
GANは生成ネットワーク,識別ネットワークの二つを競い合わせることで生成モデルを獲得する.
画像生成分野でよく使用される.
選択肢1: ResNetは画像分類タスクで用いられるCNNモデルである.
選択肢2: VGG16は画像分類タスクで用いられるCNNモデルである.
選択肢3: VAEは平均や分散などを求める生成モデルである.
選択肢3: 上述の通りである.

-------

問9

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

データが少量しかないなどの理由で,対象のタスクを学習させることが困難なときに,関連する別のタスクで学習し,その学習済みの特徴やパラメータなどを利用することで効率的に対象のタスクを学習することができる.これを（ア）という.

1. 強化学習
1. アンサンブル学習
1. 転移学習
1. マルチタスク学習

正解：3

【解説】  
正解は3である.
選択肢1：強化学習は行動を学習する手法のことである.
選択肢2：アンサンブル学習は複数の学習器を組み合わせて予測する手法のことである.
選択肢3：

問題文のとおりである.
選択肢4：同時に複数の識別

問題に対応できるように学習する手法のことである.

-------

問10

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングは,ニューラルネットワークを多層化したものであり,観測データから本質的な情報である（ア）を自動的に抽出できる点が特徴である.また,従来の機械学習手法と比べると,（イ）という性質も持っている.

1. 特徴量
1. 潜在変数
1. モデル
1. 訓練データ

正解：1

-------

問11

（イ）に当てはまらない選択肢を 1 つ選べ.

ディープラーニングは,ニューラルネットワークを多層化したものであり,観測データから本質的な情報である（ア）を自動的に抽出できる点が特徴である.また,従来の機械学習手法と比べると,（イ）という性質も持っている.

1. 学習に必要なパラメータ数が多い
1. 結果の解釈性・説明性に優れている
1. 計算量が多い
1. より複雑な関数を近似できる

正解：2

-------

問12

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

機械学習においては過学習を避けるために,訓練誤差ではなく汎化誤差を可能なかぎり小さくする手法である（ア）を用いることが多い.また複数のモデルの予測結果の平均を利用する（イ）がある.他にもディープニューラルネットワーク（DNN）に対しては,ランダムに一定の割合のノードを削除して学習を行う（ウ）が有効とされている.（ア）手法にはいくつかのパラメータをスパースにする（エ）などがある.

1. 正規化
1. 因子化
1. 標準化
1. 正則化

正解：4

【解説】  
正解は4である。
汎化誤差を下げるためには正則化が用いられることが多い。
正則化とは損失関数の値とともにモデルのパラメータの二乗和を最小になるように学習することで、パラメータが小さくなり過学習の対策となる。
選択肢1: 正規化は統計の分野では、平均が0かつ分散を1にすることが一般的である。
選択肢2: 間違い。
選択肢3: 間違い。
選択肢4: 上述の通りである。

-------

問13

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

機械学習においては過学習を避けるために,訓練誤差ではなく汎化誤差を可能なかぎり小さくする手法である（ア）を用いることが多い.また複数のモデルの予測結果の平均を利用する（イ）がある.他にもディープニューラルネットワーク（DNN）に対しては,ランダムに一定の割合のノードを削除して学習を行う（ウ）が有効とされている.（ア）手法にはいくつかのパラメータをスパースにする（エ）などがある.

1. アンサンブル学習
1. ミニバッチ学習
1. 平均プーリング
1. 転移学習

正解：1

【解説】  
正解は1である。
複数のモデルを使用し、全体の汎化性能をあげる手法をアンサンブル学習と呼ぶ。
選択肢1: 上述の通りである。
選択肢2: ミニバッチ学習とはデータをバッチの単位に分割し、効率よく学習させることである。
選択肢3: CNNなどで使われる手法である。
選択肢4: 学習済みのモデルを用いて、新たなタスクを解く手法である。

-------

問14

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

機械学習においては過学習を避けるために,訓練誤差ではなく汎化誤差を可能なかぎり小さくする手法である（ア）を用いることが多い.また複数のモデルの予測結果の平均を利用する（イ）がある.他にもディープニューラルネットワーク（DNN）に対しては,ランダムに一定の割合のノードを削除して学習を行う（ウ）が有効とされている.（ア）手法にはいくつかのパラメータをスパースにする（エ）などがある.

1. スタッキング
1. バギング
1. ドロップアウト
1. 重みの制約

正解：3

【解説】  
正解は3である。
ディープラーニングではドロップアウトを使って汎化性能を向上させている。ドロップアウトは非常に効果があり、現在では欠かせない技術となっている。
選択肢1: アンサンブル学習の一つで、モデルを積み上げて性能を向上させる手法である。
選択肢2: アンサンブル学習の一つで、複数のモデルを別々に学習させ、各モデルの平均や多数決によって最終的な判断をする手法である。
選択肢3: 上述の通りである。
選択肢4: 間違い。

-------

問15

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

機械学習においては過学習を避けるために,訓練誤差ではなく汎化誤差を可能なかぎり小さくする手法である（ア）を用いることが多い.また複数のモデルの予測結果の平均を利用する（イ）がある.他にもディープニューラルネットワーク（DNN）に対しては,ランダムに一定の割合のノードを削除して学習を行う（ウ）が有効とされている.（ア）手法にはいくつかのパラメータをスパースにする（エ）などがある.

1. Lasso
1. Ridge
1. Elastic Net

正解：1

【解説】  
正解は1である。
正則化にはL1正則化であるLasso正則化と、L2正則化であるRidge正則化の二種類が存在する。L1正則化を使用するとスパースになる。
選択肢1: 上述の通りである。
選択肢2: Ridge正則化を使用してもスパースにはならない。
選択肢3: Elastic NetはLasso正則化とRidge正則化の中間である。

-------

問16

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

ディープニューラルネットワーク（DNN）の普及に貢献した一つの要素に,（ア）を克服する手法が提案されたことがある.（ア）は誤差逆伝播法において,（イ）ことによって生じるとされている.（ア）に対処するための方法として,あらかじめ良い重みの初期値を計算する（ウ）や,活性化関数に（エ）を利用する方法などがある.

1. 勾配消失問題
1. 非線形分離問題
1. 局所解へのトラップ
1. ノーフリーランチ定理

正解：1

【解説】  
正解は1である。
ディープニューラルネットワークにおいて層が深いと、誤差逆伝播法のときに誤差がどんどん小さくなり学習が収束しない問題がある。これを勾配消失問題と呼ぶ。
選択肢1: 上述の通りである。
選択肢2: 非線形になると分離できない
問題のことであり、単純なパーセプトロンで起こる。
選択肢3: 誤差逆伝播法に関係があるのは勾配消失
問題である。
選択肢4: 組み合わせ最適化の定理である。

-------

問17

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープニューラルネットワーク（DNN）の普及に貢献した一つの要素に,（ア）を克服する手法が提案されたことがある.（ア）は誤差逆伝播法において,（イ）ことによって生じるとされている.（ア）に対処するための方法として,あらかじめ良い重みの初期値を計算する（ウ）や,活性化関数に（エ）を利用する方法などがある.

1. 入力層に近づくにつれて誤差が急速に小さくなってしまう
1. 出力層に近づくにつれて誤差が急速に小さくなってしまう
1. 入力層に近づくにつれて誤差が急速に大きくなってしまう
1. 出力層に近づくにつれて誤差が急速に大きくなってしまう

正解：1

【解説】  
正解は1である。
ディープニューラルネットワークにおいて層が深いと、誤差逆伝播法のときに誤差がどんどん小さくなり学習が収束しない問題がある。これを勾配消失問題と呼ぶ。
選択肢1: 正しい。どんどん小さくなり入力層では誤差が小さくなってしまう。
選択肢2: 間違い。「入力層に近づく」が正しい。
選択肢3: 間違い。「急速に小さく」が正しい。
選択肢4: 間違い。入力層に近づくにつれ誤差が急速に小さくなることである。

-------

問18

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープニューラルネットワーク（DNN）の普及に貢献した一つの要素に,（ア）を克服する手法が提案されたことがある.（ア）は誤差逆伝播法において,（イ）ことによって生じるとされている.（ア）に対処するための方法として,あらかじめ良い重みの初期値を計算する（ウ）や,活性化関数に（エ）を利用する方法などがある.

1. 前処理
1. 事前学習
1. ランダムサンプリング
1. 逐次学習

正解：2

【解説】  
正解は2である。
勾配消失
問題はモデルのパラメータの初期値に対して依存する。モデルを事前学習させることで安定した学習が可能となり、勾配消失
問題を克服できると考えられる。
選択肢1: 間違い。
選択肢2: 上述の通りである。
選択肢3: 間違い。
選択肢4: 間違い。

-------

問19

（エ）にあてはまる選択肢を 1 つ選べ.

ディープニューラルネットワーク（DNN）の普及に貢献した一つの要素に,（ア）を克服する手法が提案されたことがある.（ア）は誤差逆伝播法において,（イ）ことによって生じるとされている.（ア）に対処するための方法として,あらかじめ良い重みの初期値を計算する（ウ）や,活性化関数に（エ）を利用する方法などがある.

1. 正規化線形関数
1. 双曲線正接関数
1. シグモイド関数
1. ステップ関数

正解：1

【解説】  
正解は1である。
正規化線形関数はReLU関数とも呼ばれ、微分値が0以上の場合はそのままの値、0以下の場合は0となる。
この性質により誤差逆伝播の際に、重みが小さくなるのを防ぐことができる。
選択肢1: 上述の通りである。
選択肢2: Tanh関数とも呼ばれる。Tanh関数よりもReLU関数の方が勾配消失
問題が起こりづらい。
選択肢3: 勾配消失
問題が起こりやすい。
選択肢4: 微分値は常に0なので、ほとんどのニューラルネットワークでは使用されない。

-------

問20

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

大規模なディープニューラルネットワーク（DNN）の学習では学習するべきパラメータ数が膨大となるため,処理の高速化が必要となる.2012 年に提案された分散並列技術である（ア）や画像処理に特化したプロセッサの（イ）は大規模なニューラルネットワークの学習を実現するために利用されてきた.また,大規模なニューラルネットワークの学習が困難となる原因の一つとして,ある層の入力がそれより下層の学習が進むにつれて変化する（ウ）がある.（ウ）を防ぐために出力値の分布の偏りを抑制する（エ）が 2015 年に提案されている.

1. Hadoop
1. ReNet
1. DistBelief
1. MapReduce

正解：3

【解説】  
正解は3である。
DistBeliefはGoogleが開発した深層分散学習のフレームワークである。これは論文も出されていて、深層分散学習の仕組みを理解できる。
選択肢1: 分散技術を用いたアプリケーションである。
選択肢2: ResNetはCNNを用いた層の深い画像分類器である。
選択肢3: 上述の通りである。
選択肢4: 並列処理を行うためのプログラミングモデルである。

-------

問21

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

ß大規模なディープニューラルネットワーク（DNN）の学習では学習するべきパラメータ数が膨大となるため,処理の高速化が必要となる.2012 年に提案された分散並列技術である（ア）や画像処理に特化したプロセッサの（イ）は大規模なニューラルネットワークの学習を実現するために利用されてきた.また,大規模なニューラルネットワークの学習が困難となる原因の一つとして,ある層の入力がそれより下層の学習が進むにつれて変化する（ウ）がある.（ウ）を防ぐために出力値の分布の偏りを抑制する（エ）が 2015 年に提案されている.

1. GPU
1. InfniBand
1. CPU
1. FPGA

正解：1

【解説】  
正解は1である。
画像処理に特化したGPUをディープラーニングの学習に使うことで、学習速度が向上しより深い層のニューラルネットでも学習することができるようになった。このようなGPUをGPGPUと呼ぶ。
選択肢1: 上述の通りである。
選択肢2: 非常に高い信頼度のクラスタ用のアーキテクチャである。
選択肢3: 画像処理に特化していない。
選択肢4: ハード回路のことであり、ディープラーニングの学習には使用しない。

-------

問22

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

大規模なディープニューラルネットワーク（DNN）の学習では学習するべきパラメータ数が膨大となるため,処理の高速化が必要となる.2012 年に提案された分散並列技術である（ア）や画像処理に特化したプロセッサの（イ）は大規模なニューラルネットワークの学習を実現するために利用されてきた.また,大規模なニューラルネットワークの学習が困難となる原因の一つとして,ある層の入力がそれより下層の学習が進むにつれて変化する（ウ）がある.（ウ）を防ぐために出力値の分布の偏りを抑制する（エ）が 2015 年に提案されている.

1. 過学習
1. 勾配消失問題
1. 勾配爆発問題
1. 内部共変量シフト

正解：4

【解説】  
正解は4である。
大規模なニューラルネットワークを学習すると、ある層の入力がそれより仮想の学習が進むにつれて変化してしまうことがある。これにより学習が止まってしまうことが考えられる。このことを内部共変量シフトと呼ぶ。
選択肢1: 訓練データに対しては性能が良いが、未知のデータに対して性能が悪くなってしまう問題である。
選択肢2: 誤差逆伝播法のときに、誤差がどんどん小さくなっていき学習が収束しない問題である。
選択肢3: 誤差逆伝播法のときに、誤差が大きくなっていき学習が収束しない問題である。
選択肢4: 上述の通りである。

-------

問23

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

大規模なディープニューラルネットワーク（DNN）の学習では学習するべきパラメータ数が膨大となるため,処理の高速化が必要となる.2012 年に提案された分散並列技術である（ア）や画像処理に特化したプロセッサの（イ）は大規模なニューラルネットワークの学習を実現するために利用されてきた.また,大規模なニューラルネットワークの学習が困難となる原因の一つとして,ある層の入力がそれより下層の学習が進むにつれて変化する（ウ）がある.（ウ）を防ぐために出力値の分布の偏りを抑制する（エ）が 2015 年に提案されている.

1. 平滑化
1. バッチ正規化
1. データ拡張
1. L2正則化

正解：2

【解説】  
正解は2である。
内部共変量シフトの対策はバッチ正規化が使用される。各層で出力を正規化することで、層が深くなっても入力の分布の変化が少なくなると考えられる。
選択肢1: 間違い。
選択肢2: 上述の通りである。
選択肢3: 画像処理などにおいてデータを増やして汎化性能を上げる手法である。
選択肢4: 過学習への対策である。

-------

問24

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

畳み込みニューラルネットワークは,畳み込み層とプーリング層を積み上げた構成をしている.画像データを用いた場合,畳み込み層では,出力画像のサイズを調整するために元の画像の周りを固定の値で埋める（ア）を行う.プーリング層では畳み込み層の出力を圧縮するプーリングを行う,（イ）などの手法がある.

1. パディング
1. ストライド
1. 回帰代入法
1. ランダムサンプリング

正解：1

【解説】  
正解は1である。
畳み込み層では入力データの周りを固定の値で埋めるパディングを行う。主な目的は出力サイズを調整するためである。
選択肢1: 上述の通りである。
選択肢2: ストライドは畳み込みのフィルターを動かす幅のことを指す。
選択肢3: 間違い。
選択肢4: 間違い。

-------

問25

（イ）に当てはまらない選択肢を 1 つ選べ.

畳み込みニューラルネットワークは,畳み込み層とプーリング層を積み上げた構成をしている.画像データを用いた場合,畳み込み層では,出力画像のサイズを調整するために元の画像の周りを固定の値で埋める（ア）を行う.プーリング層では畳み込み層の出力を圧縮するプーリングを行う,（イ）などの手法がある.

1. 最大プーリング
1. 平均プーリング
1. Lpプーリング
1. 誤差プーリング

正解：4

【解説】  
正解は4である。
プーリングは周りの平均値で圧縮する平均プーリング、周りの最大値で圧縮する最大プーリング、周りの値をp乗しその標準偏差をとるLpプーリングなどが存在する。
誤差プーリングは存在しない。

-------

問26

（ア）にあてはまらない選択肢を 1 つ選べ.

ニューラルネットワークには（ア）などの多くのハイパーパラメータが存在し,これらの値が精度に大きな影響を与える.ハイパーパラメータのチューニング方法としては,パラメータの候補値を指定し,それらの組み合わせを調べる（イ）などがある.また,近年は,ハイパーパラメータを含め最適化
問題とする（ウ）が効率的なチューニング方法として注目をあびている.

1. 隠れ層の数
1. 活性化関数
1. 学習率
1. バイアス

正解：4

【解説】  
正解は4である。
ハイパーパラメータは学習をする前に人手で設定しなければいけないパラメータのことを指す。
また、バイアスはモデルのパラメータの一部なので学習される。したがってバイアスはハイパーパラメータではない。
その他の選択肢は全てハイパーパラメータである。

-------

問27

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークには（ア）などの多くのハイパーパラメータが存在し,これらの値が精度に大きな影響を与える.ハイパーパラメータのチューニング方法としては,パラメータの候補値を指定し,それらの組み合わせを調べる（イ）などがある.また,近年は,ハイパーパラメータを含め最適化
問題とする（ウ）が効率的なチューニング方法として注目をあびている.

1. ホールドアウト
1. ランダムサーチ
1. クロスバリデーション
1. グリッドサーチ

正解：4

【解説】  
正解は4である。
ハイパーパラメータを求める方法にはグリッドサーチやランダムサーチがある。
グリッドサーチは適切だと考えられるパラメータを複数用意し、それらの値の組み合わせを全通り総当たりで行い、最も良いハイパーパラメータを探す方法である。
ランダムサーチは考えられるパラメータの範囲を決め、ランダムにパラメータを組み合わせて学習させ、最も良いハイパーパラメータを探す方法である。
選択肢1: モデルを学習する際に、データセットを訓練データと検証データに分割し、訓練データで学習したモデルを検証データで評価する手法である。
選択肢2: ランダムで探索するのがランダムサーチである。
選択肢3: モデルを学習する際に、データセットを分割し、訓練データと検証データを交代させて精度を測る手法である。
選択肢4: 上述の通りである。

-------

問28

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークには（ア）などの多くのハイパーパラメータが存在し,これらの値が精度に大きな影響を与える.ハイパーパラメータのチューニング方法としては,パラメータの候補値を指定し,それらの組み合わせを調べる（イ）などがある.また,近年は,ハイパーパラメータを含め最適化
問題とする（ウ）が効率的なチューニング方法として注目をあびている.

1. 蒸留
1. ベイズ最適化
1. 多目的最適化
1. ファインチューニング

正解：2

【解説】  
正解は2である。
近年では、ベイズ最適化もハイパーパラメータの最適化の方法として注目されている。これは過去の試行結果から次に行う範囲を確率分布を用いて計算する手法である。
選択肢1: 蒸留はモデルのパラメータを小さくする手法の一つである。
選択肢2: 上述の通りである。
選択肢3: 間違いである。
選択肢4: 既存のモデルの一部を利用して新たなモデルを解くために再学習する手法である。

-------

問29

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

自己符号化器はニューラルネットワークによる（ア）の代表的な応用であり,出力が入力に近づくようにニューラルネットを学習させる.主に（イ）のために利用されることが多く,活性化関数に恒等写像を用いた場合の 3 層の自己符号化器は（ウ）と同様の結果を返す.自己符号化器を多層化すると,ディープニューラルネット同様に勾配消失問題が生じるため,複雑な内部表現を得ることは困難であった.この問題に対して 2006 年頃に（エ）らは,単層の自己符号化器に分割し入力層から繰り返し学習させる（オ）を積層自己符号化器に適用することで,汎用的な自己符号化器の利用を可能とした.また,自己符号化器の代表的な応用例として（カ）がある.

1. 教師あり学習
1. 教師なし学習
1. 半教師あり学習
1. 強化学習

正解：2

-------

問30

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

自己符号化器はニューラルネットワークによる（ア）の代表的な応用であり,出力が入力に近づくようにニューラルネットを学習させる.主に（イ）のために利用されることが多く,活性化関数に恒等写像を用いた場合の 3 層の自己符号化器は（ウ）と同様の結果を返す.自己符号化器を多層化すると,ディープニューラルネット同様に勾配消失問題が生じるため,複雑な内部表現を得ることは困難であった.この問題に対して 2006 年頃に（エ）らは,単層の自己符号化器に分割し入力層から繰り返し学習させる（オ）を積層自己符号化器に適用することで,汎用的な自己符号化器の利用を可能とした.また,自己符号化器の代表的な応用例として（カ）がある.

1. 回帰
1. 2クラス分類
1. 多クラス分類
1. 次元削減

正解：4

-------

問31

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

自己符号化器はニューラルネットワークによる（ア）の代表的な応用であり,出力が入力に近づくようにニューラルネットを学習させる.主に（イ）のために利用されることが多く,活性化関数に恒等写像を用いた場合の 3 層の自己符号化器は（ウ）と同様の結果を返す.自己符号化器を多層化すると,ディープニューラルネット同様に勾配消失問題が生じるため,複雑な内部表現を得ることは困難であった.この問題に対して 2006 年頃に（エ）らは,単層の自己符号化器に分割し入力層から繰り返し学習させる（オ）を積層自己符号化器に適用することで,汎用的な自己符号化器の利用を可能とした.また,自己符号化器の代表的な応用例として（カ）がある.

1. 線形回帰
1. 主成分分析（PCA）
1. ロジスティック回帰
1. k平均法

正解：2

-------

問32

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

自己符号化器はニューラルネットワークによる（ア）の代表的な応用であり,出力が入力に近づくようにニューラルネットを学習させる.主に（イ）のために利用されることが多く,活性化関数に恒等写像を用いた場合の 3 層の自己符号化器は（ウ）と同様の結果を返す.自己符号化器を多層化すると,ディープニューラルネット同様に勾配消失問題が生じるため,複雑な内部表現を得ることは困難であった.この問題に対して 2006 年頃に（エ）らは,単層の自己符号化器に分割し入力層から繰り返し学習させる（オ）を積層自己符号化器に適用することで,汎用的な自己符号化器の利用を可能とした.また,自己符号化器の代表的な応用例として（カ）がある.

1. Hinton
1. Fukushima
1. Krizhvsky
1. Goodfellow

正解：1

-------

問33

（オ）に最もよくあてはまる選択肢を 1 つ選べ.

自己符号化器はニューラルネットワークによる（ア）の代表的な応用であり,出力が入力に近づくようにニューラルネットを学習させる.主に（イ）のために利用されることが多く,活性化関数に恒等写像を用いた場合の 3 層の自己符号化器は（ウ）と同様の結果を返す.自己符号化器を多層化すると,ディープニューラルネット同様に勾配消失問題が生じるため,複雑な内部表現を得ることは困難であった.この問題に対して 2006 年頃に（エ）らは,単層の自己符号化器に分割し入力層から繰り返し学習させる（オ）を積層自己符号化器に適用することで,汎用的な自己符号化器の利用を可能とした.また,自己符号化器の代表的な応用例として（カ）がある.

1. 誤差逆伝播法
1. バッチ正規化
1. 層ごとの貪欲法
1. 確率的勾配降下法

正解：3

-------

問34

（カ）に当てはまらない選択肢を 1 つ選べ.

自己符号化器はニューラルネットワークによる（ア）の代表的な応用であり,出力が入力に近づくようにニューラルネットを学習させる.主に（イ）のために利用されることが多く,活性化関数に恒等写像を用いた場合の 3 層の自己符号化器は（ウ）と同様の結果を返す.自己符号化器を多層化すると,ディープニューラルネット同様に勾配消失問題が生じるため,複雑な内部表現を得ることは困難であった.この問題に対して 2006 年頃に（エ）らは,単層の自己符号化器に分割し入力層から繰り返し学習させる（オ）を積層自己符号化器に適用することで,汎用的な自己符号化器の利用を可能とした.また,自己符号化器の代表的な応用例として（カ）がある.

1. ノイズ除去
1. ニューラルネットの事前学習
1. 異常検知
1. 仮想計測

正解：4

-------

問35

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

RNN は（ア）系列データの処理に長けているニューラルネットワークである.RNN は,（イ）勾配消問題が起きやすいという特徴を持っていたが,RNN の一種である LSTM では（ウ）を含む LSTM Block を組み込むことで,長期間の系列情報に対しても勾配消失せずに学習を行うことができる.

1. 入力が固定長となる
1. 前処理が必要でない
1. 時間依存の情報が含まれる
1. 空間的な情報を持つ

正解：3

-------

問36

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

RNN は（ア）系列データの処理に長けているニューラルネットワークである.RNN は,（イ）勾配消問題が起きやすいという特徴を持っていたが,RNN の一種である LSTM では（ウ）を含む LSTM Block を組み込むことで,長期間の系列情報に対しても勾配消失せずに学習を行うことができる.

1. 全てのノードが互いに結合した構造を持つため
1. 1層あたりのノード数が多くなるため
1. 内部にループ構造を持つため

正解：4

-------

問37

（ウ）に当てはまらない選択肢を 1 つ選べ.

RNN は（ア）系列データの処理に長けているニューラルネットワークである.RNN は,（イ）勾配消問題が起きやすいという特徴を持っていたが,RNN の一種である LSTM では（ウ）を含む LSTM Block を組み込むことで,長期間の系列情報に対しても勾配消失せずに学習を行うことができる.

1. メモリー・セル
1. 入力ゲート
1. 抽出ゲート
1. 忘却ゲート

正解：3

-------

問38

RNN についての説明として誤っている選択肢を1 つ選べ.

1. RNN ではネットワークにループ構造が含まれるため,中間層が 1 層であっても勾配消問題が起きてしまう
1. 音声認識では RNN の一種であるエルマン・ネットワークが利用されてきた
1. RNN の学習には勾配消問題を避けることのできる通時的誤差逆伝播法（back-propagation through time法）が利用される
1. RNN の一種である LSTM は機械翻訳や画像からのキャプション生成などに応用できる

正解：3

-------

問39

（ア）に当てはまらない選択肢を 1 つ選べ.

ディープニューラルネットワーク（DNN）の学習の目的は（ア）を最小化することであり,この最適化のために勾配降下法が利用される.しかし,勾配降下法にはパラメータの勾配を数値的に求めると（イ問題があり,このよう問題を避けるために誤差逆伝播法が利用される.またディープラーニングには過学習問題もある.過学習とは（ウ）は小さいにも関わらず,（エ）が小さくならないことであり,これら問題を克服するために様々な手法の開発が進められている.

1. 損失関数
1. コスト関数
1. 誤差関数
1. 出力関数

正解：4

-------

問40

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープニューラルネットワーク（DNN）の学習の目的は（ア）を最小化することであり,この最適化のために勾配降下法が利用される.しかし,勾配降下法にはパラメータの勾配を数値的に求めると（イ問題があり,このよう問題を避けるために誤差逆伝播法が利用される.またディープラーニングには過学習問題もある.過学習とは（ウ）は小さいにも関わらず,（エ）が小さくならないことであり,これら問題を克服するために様々な手法の開発が進められている.

1. 計算量が膨大となってしまう
1. 勾配が消失してしまう
1. 過学習が起きてしまう

正解：1

-------

問41

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープニューラルネットワーク（DNN）の学習の目的は（ア）を最小化することであり,この最適化のために勾配降下法が利用される.しかし,勾配降下法にはパラメータの勾配を数値的に求めると（イ問題があり,このよう問題を避けるために誤差逆伝播法が利用される.またディープラーニングには過学習問題もある.過学習とは（ウ）は小さいにも関わらず,（エ）が小さくならないことであり,これら問題を克服するために様々な手法の開発が進められている.

1. 訓練誤差
1. 期待誤差
1. 汎化誤差
1. 絶対誤差

正解：1

-------

問42

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープニューラルネットワーク（DNN）の学習の目的は（ア）を最小化することであり,この最適化のために勾配降下法が利用される.しかし,勾配降下法にはパラメータの勾配を数値的に求めると（イ問題があり,このよう問題を避けるために誤差逆伝播法が利用される.またディープラーニングには過学習問題もある.過学習とは（ウ）は小さいにも関わらず,（エ）が小さくならないことであり,これら問題を克服するために様々な手法の開発が進められている.

1. 訓練誤差
1. 期待誤差
1. 汎化誤差
1. 絶対誤差

正解：3

-------

問43

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

勾配降下法においてパラメータの更新量を決める（ア）の決定は重要である.例えば（ア）が小さすぎると（イ）などの課題が生じるため,（ウ）などの様々な（ア）調整手法が提案されている.

1. バイアス
1. 学習率
1. ストライド
1. イテレーション

正解：2

-------

問44

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

勾配降下法においてパラメータの更新量を決める（ア）の決定は重要である.例えば（ア）が小さすぎると（イ）などの課題が生じるため,（ウ）などの様々な（ア）調整手法が提案されている.

1. 収束が遅くなる
1. パラメータの値が発散してしまう
1. 学習に必要なパラメータ数が多くなる

正解：1

-------

問45

（ウ）に当てはまらない選択肢を 1 つ選べ.

勾配降下法においてパラメータの更新量を決める（ア）の決定は重要である.例えば（ア）が小さすぎると（イ）などの課題が生じるため,（ウ）などの様々な（ア）調整手法が提案されている.

1. Adam
1. RMSprop
1. モメンタム
1. スタッキング

正解：4

-------

問46

CNN で行われる畳み込み演算の計算処理について考える.5×5 のサイズの画像に対して,3×3 のフィルタをパディング 1,ストライド 1 で適用した場合の出力の図のサイズを答えよ.

1. 3×3
1. 4×4
1. 5×5
1. 6×6

正解：3

-------

問47

（ア）に当てはまらない選択肢を 1 つ選べ.

ディープニューラルネットワーク（DNN）のパラメータ最適化手法として（ア）などの勾配降下法が適用される.しかし,勾配降下法には（イ）など問題があり,これら問題に対処するために,学習率をパラメータに適応させることで自動的に学習率を調整することができる（ウ）や勾配の平均と分散をオンラインで推定し利用する（エ）が利用されてきた.

1. バッチ勾配降下法
1. ミニバッチ勾配降下法
1. 確率的勾配降下法
1. 確定的勾配降下法

正解：4

-------

問48

（イ）に当てはまらない選択肢を 1 つ選べ.

ディープニューラルネットワーク（DNN）のパラメータ最適化手法として（ア）などの勾配降下法が適用される.しかし,勾配降下法には（イ）など問題があり,これら問題に対処するために,学習率をパラメータに適応させることで自動的に学習率を調整することができる（ウ）や勾配の平均と分散をオンラインで推定し利用する（エ）が利用されてきた.

1. 谷での振動
1. プラトーへのトラッ
1. 局所的最適解への収束
1. 大域的最適解への収束

正解：4

-------

問49

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープニューラルネットワーク（DNN）のパラメータ最適化手法として（ア）などの勾配降下法が適用される.しかし,勾配降下法には（イ）など問題があり,これら問題に対処するために,学習率をパラメータに適応させることで自動的に学習率を調整することができる（ウ）や勾配の平均と分散をオンラインで推定し利用する（エ）が利用されてきた.

1. Adagrad
1. 重み共有
1. ドロップアウト
1. モメンタム

正解：1

-------

問50

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープニューラルネットワーク（DNN）のパラメータ最適化手法として（ア）などの勾配降下法が適用される.しかし,勾配降下法には（イ）など問題があり,これら問題に対処するために,学習率をパラメータに適応させることで自動的に学習率を調整することができる（ウ）や勾配の平均と分散をオンラインで推定し利用する（エ）が利用されてきた.

1. Adam
1. AdaGrad
1. Adadelta
1. AdaBoost

正解：1

-------

問51

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

機械学習の分野において有名な二つの定理について扱う.（ア）は,認知できる全ての客観的な特徴に基づくと全ての対象は同程度に類似している,つまり特徴を選択しなければ表現の類似度に基づく分類は不可能であることを示している.（イ）は,全てのタスクに対して常に他よりすぐれている万能的なアルゴリズムは存在しないことを示している.

1. バーニーおじさんのルール
1. 次元の呪い
1. ノーフリーランチ定理
1. 醜いアヒルの子の定理

正解：4

-------

問52

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

機械学習の分野において有名な二つの定理について扱う.（ア）は,認知できる全ての客観的な特徴に基づくと全ての対象は同程度に類似している,つまり特徴を選択しなければ表現の類似度に基づく分類は不可能であることを示している.（イ）は,全てのタスクに対して常に他よりすぐれている万能的なアルゴリズムは存在しないことを示している.

1. バーニーおじさんのルール
1. 次元の呪い
1. ノーフリーランチ定理
1. 醜いアヒルの子の定理

正解：3

【解説】  
正解は4である.
選択肢1：学習に用いるデータ量の目安となる経験則
選択肢2：データの次元が増加すると問題の算法が指数関数的に大きくなること
選択肢3：全てのタスクに対して常に他よりすぐれている万能的なアルゴリズムは存在しないこと
選択肢4：認知できる全ての客観的な特徴に基づくと全ての対象は同程度に類似している,つまり特徴を選択しなければ表現の類似度に基づく分類は不可能である,ということ

-------

問53

（ア）に当てはまらない選択肢を 1 つ選べ.

ディープラーニングのモデルは,確定的モデルと確率的モデルに分類することができる.これらのモデルの例として,確定的モデルに（ア）や確率的モデルに（イ）がある.

1. 畳み込みニューラルネット
1. 深層信念ネットワーク
1. 積層自己符号化器
1. 再帰型ニューラルネット

正解：2

-------

問54

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングのモデルは,確定的モデルと確率的モデルに分類することができる.これらのモデルの例として,確定的モデルに（ア）や確率的モデルに（イ）がある.

1. ベイジアンネットワーク
1. サポートベクターマシン
1. 深層ボルツマンマシン（​Boltzmann machine​）
1. 雑音除去自己符号化器

正解：3

-------

問55

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングを含めて機械学習において精度の高い学習をするためには,観測データの適切な前処理が必須である.異なるスケールの特徴量を同時に扱えるようにするために,平均を 0 に分散を 1 に規格化する（ア）や,特徴量の線形結合からデータ内の分散が大きくなるような特徴量を得る（イ）などは広く利用されている.また,画像処理の分野においては,減算正規化と除算正規化の処理を行う（ウ）などが前処理として利用され,（エ）などの画像処理に特化したライブラリで行うことができる.また,自然言語処理の分野においては,文章に単語が含まれているかどうかを考えてテキストデータを数値化する（オ）や文章に含まれる単語の重要度を特徴量とする（カ）などがある.

1. 中心化
1. 標準化
1. 分散化
1. 抽象化

正解：2

-------

問56

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングを含めて機械学習において精度の高い学習をするためには,観測データの適切な前処理が必須である.異なるスケールの特徴量を同時に扱えるようにするために,平均を 0 に分散を 1 に規格化する（ア）や,特徴量の線形結合からデータ内の分散が大きくなるような特徴量を得る（イ）などは広く利用されている.また,画像処理の分野においては,減算正規化と除算正規化の処理を行う（ウ）などが前処理として利用され,（エ）などの画像処理に特化したライブラリで行うことができる.また,自然言語処理の分野においては,文章に単語が含まれているかどうかを考えてテキストデータを数値化する（オ）や文章に含まれる単語の重要度を特徴量とする（カ）などがある.

1. 主成分分析（PCA）
1. 因子分析
1. 線形判別分析
1. k平均法

正解：1

-------

問57

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングを含めて機械学習において精度の高い学習をするためには,観測データの適切な前処理が必須である.異なるスケールの特徴量を同時に扱えるようにするために,平均を 0 に分散を 1 に規格化する（ア）や,特徴量の線形結合からデータ内の分散が大きくなるような特徴量を得る（イ）などは広く利用されている.また,画像処理の分野においては,減算正規化と除算正規化の処理を行う（ウ）などが前処理として利用され,（エ）などの画像処理に特化したライブラリで行うことができる.また,自然言語処理の分野においては,文章に単語が含まれているかどうかを考えてテキストデータを数値化する（オ）や文章に含まれる単語の重要度を特徴量とする（カ）などがある.

1. 白色化
1. グレースケール化
1. 平滑化
1. 局所コントラスト正規化

正解：4

-------

問58

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングを含めて機械学習において精度の高い学習をするためには,観測データの適切な前処理が必須である.異なるスケールの特徴量を同時に扱えるようにするために,平均を 0 に分散を 1 に規格化する（ア）や,特徴量の線形結合からデータ内の分散が大きくなるような特徴量を得る（イ）などは広く利用されている.また,画像処理の分野においては,減算正規化と除算正規化の処理を行う（ウ）などが前処理として利用され,（エ）などの画像処理に特化したライブラリで行うことができる.また,自然言語処理の分野においては,文章に単語が含まれているかどうかを考えてテキストデータを数値化する（オ）や文章に含まれる単語の重要度を特徴量とする（カ）などがある.

1. OpenCV
1. mecab
1. Julius
1. OpenNLP

正解：1

-------

問59

（オ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングを含めて機械学習において精度の高い学習をするためには,観測データの適切な前処理が必須である.異なるスケールの特徴量を同時に扱えるようにするために,平均を 0 に分散を 1 に規格化する（ア）や,特徴量の線形結合からデータ内の分散が大きくなるような特徴量を得る（イ）などは広く利用されている.また,画像処理の分野においては,減算正規化と除算正規化の処理を行う（ウ）などが前処理として利用され,（エ）などの画像処理に特化したライブラリで行うことができる.また,自然言語処理の分野においては,文章に単語が含まれているかどうかを考えてテキストデータを数値化する（オ）や文章に含まれる単語の重要度を特徴量とする（カ）などがある.

1. bag-of-words
1. TF-IDF
1. word2vec
1. 形態素解析

正解：1

-------

問60

（カ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングを含めて機械学習において精度の高い学習をするためには,観測データの適切な前処理が必須である.異なるスケールの特徴量を同時に扱えるようにするために,平均を 0 に分散を 1 に規格化する（ア）や,特徴量の線形結合からデータ内の分散が大きくなるような特徴量を得る（イ）などは広く利用されている.また,画像処理の分野においては,減算正規化と除算正規化の処理を行う（ウ）などが前処理として利用され,（エ）などの画像処理に特化したライブラリで行うことができる.また,自然言語処理の分野においては,文章に単語が含まれているかどうかを考えてテキストデータを数値化する（オ）や文章に含まれる単語の重要度を特徴量とする（カ）などがある.

1. bag-of-words
1. TF-IDF
1. wod2vec
1. 形態素解析

正解：2

-------

問61

強化学習の説明として誤りである選択肢を 1 つ選べ.

1. 正解データ付きの訓練データを用意する必要がない
1. 一般的に学習には時間がかかる
1. 状態遷移を考慮することができる
1. 汎用性が高く異なるタスクへの転移が容易である

正解：4

-------

問62

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

生成モデル（generative model）とは,訓練データからそのデータの特徴を学習し,類似したデータを生成することができるモデルである.ディープニューラルネットの生成モデル（generative model）の例として,自己符号化器の潜在変数に確率分布を導入した（ア）や,訓練データと生成器が生成したデータを識別器で判別させることによって学習を進める（イ）がある.

1. CAE
1. DAE
1. VAE
1. CNN

正解：3

-------

問63

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

生成モデル（generative model）とは,訓練データからそのデータの特徴を学習し,類似したデータを生成することができるモデルである.ディープニューラルネットの生成モデル（generative model）の例として,自己符号化器の潜在変数に確率分布を導入した（ア）や,訓練データと生成器が生成したデータを識別器で判別させることによって学習を進める（イ）がある.

1. DQN
1. GAN
1. DBN
1. RNN

正解：2

-------

問64

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

（ア）はディープラーニングにおける重要な課題の一つであり,学習済みのディープニューラルネットモデルを欺くように人工的に作られたサンプルのことである.サンプルに対して微小な摂動を加えることで,作為的にモデルの誤認識を引き起こすことができる.

1. adversarial example
1. reverse example
1. wrong example
1. antagonistic example

正解：1

-------

問65

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

強化学習では,行動を学習する（ア）と（ア）が行動を加える対象である（イ）を考え,行動に応じて（イ）は（ア）に状態と（ウ）を返す.行動と状態/（ウ）の獲得を繰り返し,最も多くの（ウ）をもらえるような方策を得ることが強化学習の目的である.

1. 観測者
1. 環境
1. プレイヤー
1. エージェント

正解：4

-------

問66

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

強化学習では,行動を学習する（ア）と（ア）が行動を加える対象である（イ）を考え,行動に応じて（イ）は（ア）に状態と（ウ）を返す.行動と状態/（ウ）の獲得を繰り返し,最も多くの（ウ）をもらえるような方策を得ることが強化学習の目的である.

1. 観測者
1. 環境
1. プレイヤー
1. エージェント

正解：2

-------

問67

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

強化学習では,行動を学習する（ア）と（ア）が行動を加える対象である（イ）を考え,行動に応じて（イ）は（ア）に状態と（ウ）を返す.行動と状態/（ウ）の獲得を繰り返し,最も多くの（ウ）をもらえるような方策を得ることが強化学習の目的である.

1. 利息
1. 報酬
1. 得点

正解：2

-------

問68

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

強化学習において,行動価値関数の関数近似に畳み込みニューラルネットワークを用いた手法が（ア）である.

1. DBM
1. DNN
1. DAE
1. DQN

正解：4

-------

問69

過学習とはどのような状態のことか.選択肢から最も適切なものを 1 つ選べ.

1. 重みの状態が 0 になること
1. 活性化関数が機能しなくなること
1. 特定の訓練サンプルに対して,特化して学習すること
1. バイアスが 0 になること

正解：3

-------

問70

内部共変量シフトについて選択肢から最も適切なものを 1 つ選べ.

1. 入力の分布が学習途中で大きく変わってく問題
1. 入力の平均と分散を特定の値にする手法
1. 重みの初期値を設定する手法
1. パラメータの勾配が 0 にな問題

正解：1

-------

問71

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

確率的勾配法はディープラーニングにおいて最もよく知られる最適化アルゴリズムであり,いくつかの改善を加えたものが広く使われている.例えば,以前に適用した勾配の方向を現在のパラメータ更新にも影響させる（ア）という手法や,勾配を2乗した値を蓄積し,すでに大きく更新されたパラメータほど更新量（学習率）を小さくする（イ）や,（イ）における一度更新量が飽和した重みはもう更新されないという欠点を,指数移動平均を蓄積することにより解決した（ウ）などがある.

1. RMSprop
1. AdaGrad
1. モメンタム
1. Adam

正解：3

-------

問72

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

確率的勾配法はディープラーニングにおいて最もよく知られる最適化アルゴリズムであり,いくつかの改善を加えたものが広く使われている.例えば,以前に適用した勾配の方向を現在のパラメータ更新にも影響させる（ア）という手法や,勾配を 2 乗した値を蓄積し,すでに大きく更新されたパラメータほど更新量（学習率）を小さくする（イ）や,（イ）における一度更新量が飽和した重みはもう更新されないという欠点を,指数移動平均を蓄積することにより解決した（ウ）などがある.

1. RMSprop
1. AdaGrad
1. モメンタム
1. Adam

正解：2

-------

問73

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

確率的勾配法はディープラーニングにおいて最もよく知られる最適化アルゴリズムであり,いくつかの改善を加えたものが広く使われている.例えば,以前に適用した勾配の方向を現在のパラメータ更新にも影響させる（ア）という手法や,勾配を 2 乗した値を蓄積し,すでに大きく更新されたパラメータほど更新量（学習率）を小さくする（イ）や,（イ）における一度更新量が飽和した重みはもう更新されないという欠点を,指数移動平均を蓄積することにより解決した（ウ）などがある.

1. RMSprop
1. AdaGrad
1. モメンタム
1. Adam

正解：1

-------

問74

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングの技術を利用したシステムを開発する際,複雑な処理が比較的簡潔に記述できることから,既存のフレームワークを利用することも多い.ディープラーニングのフレームワークは複数あり,google 社提供の（ア）や（ア）のラッパーとして機能する（イ）,国内企業である PreferredNetworks 社で開発された（ウ）などがある.また,（エ）は（ウ）と同じ Define-by-Run 方式を採用している.

1. Chainer
1. Keras
1. PyTorch
1. TensorFlow

正解：4

-------

問75

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングの技術を利用したシステムを開発する際,複雑な処理が比較的簡潔に記述できることから,既存のフレームワークを利用することも多い.ディープラーニングのフレームワークは複数あり,google 社提供の（ア）や（ア）のラッパーとして機能する（イ）,国内企業である PreferredNetworks 社で開発された（ウ）などがある.また,（エ）は（ウ）と同じ Define-by-Run 方式を採用している.

1. Chainer
1. Keras
1. PyTorch
1. TensorFlow

正解：2

-------

問76

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングの技術を利用したシステムを開発する際,複雑な処理が比較的簡潔に記述できることから,既存のフレームワークを利用することも多い.ディープラーニングのフレームワークは複数あり,google 社提供の（ア）や（ア）のラッパーとして機能する（イ）,国内企業である PreferredNetworks 社で開発された（ウ）などがある.また,（エ）は（ウ）と同じ Define-by-Run 方式を採用している.

1. Chainer
1. Keras
1. PyTorch
1. TensorFlow

正解：1

-------

問77

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングの技術を利用したシステムを開発する際,複雑な処理が比較的簡潔に記述できることから,既存のフレームワークを利用することも多い.ディープラーニングのフレームワークは複数あり,google 社提供の（ア）や（ア）のラッパーとして機能する（イ）,国内企業である PreferredNetworks 社で開発された（ウ）などがある.また,（エ）は（ウ）と同じ Define-by-Run 方式を採用している.

1. Chainer
1. Keras
1. PyTorch
1. TensorFlow

正解：3

-------

問78

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークの学習には独自問題が生じる.層を深くするほど,入力層に近い層で学習が行われにくくなる（ア問題が起こったり,パラメータがつくる空間が高次元になり,その空間内の局所最適解や（イ）にトラップされることが多くなる.

1. トロッコ
1. 勾配消失
1. スケジューリング
1. 深層忘却

正解：2

-------

問79

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークの学習には独自問題が生じる.層を深くするほど,入力層に近い層で学習が行われにくくなる（ア問題が起こったり,パラメータがつくる空間が高次元になり,その空間内の局所最適解や（イ）にトラップされることが多くなる.

1. 中点
1. 変曲点
1. 特異点
1. 鞍点

正解：4

-------

問80

自己符号化器（Autoencoder）は,出力が入力と同じものに近づくことを目指して学習する.（ア）のアルゴリズムであり,（イ）が可能になる.このときの（ウ）が入力の特徴を抽出した表現となる.

1. 教師あり学習
1. 教師なし学習
1. 強化学習
1. マルチタスク学習

正解：2

-------

問81

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

自己符号化器（Autoencoder）は,出力が入力と同じものに近づくことを目指して学習する.（ア）のアルゴリズムであり,（イ）が可能になる.このときの（ウ）が入力の特徴を抽出した表現となる.

1. 誤差逆伝播法
1. 勾配降下法
1. 次元削減
1. 欠損値の処理

正解：3

-------

問82

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

自己符号化器（Autoencoder）は,出力が入力と同じものに近づくことを目指して学習する.（ア）のアルゴリズムであり,（イ）が可能になる.このときの（ウ）が入力の特徴を抽出した表現となる.

1. 入力層
1. 隠れ層
1. 出力層
1. なし

正解：2

-------

問83

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

機械学習において,重み更新に関わる単位として,（ア）と（イ）がある.（ア）は,重みが更新された回数であり,（イ）は訓練データを何回繰り返し学習したかを表す単位である.また一回の（ア）に用いるサンプル数は（ウ）と呼ばれる.

1. エポック
1. イテレーション
1. バッチサイズ
1. サンプル数

正解：2

-------

問84

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

機械学習において,重み更新に関わる単位として,（ア）と（イ）がある.（ア）は,重みが更新された回数であり,（イ）は訓練データを何回繰り返し学習したかを表す単位である.また一回の（ア）に用いるサンプル数は（ウ）と呼ばれる.

1. エポック
1. イテレーション
1. バッチサイズ
1. サンプル数

正解：1

-------

問85

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

機械学習において,重み更新に関わる単位として,（ア）と（イ）がある.（ア）は,重みが更新された回数であり,（イ）は訓練データを何回繰り返し学習したかを表す単位である.また一回の（ア）に用いるサンプル数は（ウ）と呼ばれる.

1. エポック
1. イテレーション
1. バッチサイズ
1. サンプル数

正解：3

-------

問86

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

活性化関数とは,ニューロンの出力に何らかの非線形な変数を加える関数である.単純パーセプトロンの出力層では（ア）が用いられ,ニューラルネットワークの中間層では,はじめ（イ）などの正規化の機能を持つ関数が好まれた.しかし現在では,誤差逆伝播で勾配が消失しやすいとい問題から,中間層では勾配消問題の影響を抑えられ,かつ簡単な（ウ）などが用いられている.また,出力層では出力の総和が 1 になるため確率的な解釈が可能になる（エ）がよく用いられる.

1. ソフトマックス関数
1. ステップ関数
1. ReLU
1. 多項式基底関数
5.Dropout
6.シグモイド関数

正解：2

-------

問87

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

活性化関数とは,ニューロンの出力に何らかの非線形な変数を加える関数である.単純パーセプトロンの出力層では（ア）が用いられ,ニューラルネットワークの中間層では,はじめ（イ）などの正規化の機能を持つ関数が好まれた.しかし現在では,誤差逆伝播で勾配が消失しやすいとい問題から,中間層では勾配消問題の影響を抑えられ,かつ簡単な（ウ）などが用いられている.また,出力層では出力の総和が 1 になるため確率的な解釈が可能になる（エ）がよく用いられる.

1. ソフトマックス関数
1. ステップ関数
1. ReLU
1. 多項式基底関数
5.Dropout
6.シグモイド関数

正解：6

-------

問88

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

活性化関数とは,ニューロンの出力に何らかの非線形な変数を加える関数である.単純パーセプトロンの出力層では（ア）が用いられ,ニューラルネットワークの中間層では,はじめ（イ）などの正規化の機能を持つ関数が好まれた.しかし現在では,誤差逆伝播で勾配が消失しやすいとい問題から,中間層では勾配消問題の影響を抑えられ,かつ簡単な（ウ）などが用いられている.また,出力層では出力の総和が 1 になるため確率的な解釈が可能になる（エ）がよく用いられる.

1. ソフトマックス関数
1. ステップ関数
1. ReLU
1. 多項式基底関数
5.Dropout
6.シグモイド関数

正解：3

-------

問89

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

活性化関数とは,ニューロンの出力に何らかの非線形な変数を加える関数である.単純パーセプトロンの出力層では（ア）が用いられ,ニューラルネットワークの中間層では,はじめ（イ）などの正規化の機能を持つ関数が好まれた.しかし現在では,誤差逆伝播で勾配が消失しやすいとい問題から,中間層では勾配消問題の影響を抑えられ,かつ簡単な（ウ）などが用いられている.また,出力層では出力の総和が 1 になるため確率的な解釈が可能になる（エ）がよく用いられる.

1. ソフトマックス関数
1. ステップ関数
1. ReLU
1. 多項式基底関数
5.Dropout
6.シグモイド関数

正解：1

-------

問90

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

大きなニューラルネットワークなどの入出力をより小さなネットワークに学習させる技術として,（ア）がある.（ア）とは,すでに学習されているモデル（教師モデル）を利用して,より小さくシンプルなモデル（生徒モデル）を学習させる手法である.こうすることにより,生徒モデルを単独で学習させる場合よりも（イ）ことができる.

1. アンサンブル学習
1. スタッキング
1. 蒸留
1. 転移学習

正解：3

-------

問91

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

大きなニューラルネットワークなどの入出力をより小さなネットワークに学習させる技術として,（ア）がある.（ア）とは,すでに学習されているモデル（教師モデル）を利用して,より小さくシンプルなモデル（生徒モデル）を学習させる手法である.こうすることにより,生徒モデルを単独で学習させる場合よりも（イ）ことができる.

1. メモリを節約する
1. 過学習を緩和する
1. 通信コストを削減する
1. 学習の総時間が短縮される

正解：2

-------

問92

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

画像データに対しては,前処理を施すことが多い.カラー画像を白黒画像に変換して計算量を削減する（ア）や,細かいノイズの影響を除去する（イ）,画素ごとの明るさをスケーリングする（ウ）などがこれに含まれる.

1. 白色化
1. グレースケール化
1. ヒストグラム平均
1. 平滑化

正解：2

-------

問93

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

画像データに対しては,前処理を施すことが多い.カラー画像を白黒画像に変換して計算量を削減する（ア）や,細かいノイズの影響を除去する（イ）,画素ごとの明るさをスケーリングする（ウ）などがこれに含まれる.

1. 白色化
1. グレースケール化
1. ヒストグラム平均
1. 平滑化

正解：4

-------

問94

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

画像データに対しては,前処理を施すことが多い.カラー画像を白黒画像に変換して計算量を削減する（ア）や,細かいノイズの影響を除去する（イ）,画素ごとの明るさをスケーリングする（ウ）などがこれに含まれる.

1. 白色化
1. グレースケール化
1. ヒストグラム平均
1. 平滑化

正解：3

-------

問95

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

畳み込みニューラルネットワークの（ア）のパラメータ数は（イ）と比較して極めて少ない.これは（ウ）によって（エ）ため,パラメータ数が減り,計算量が少なくなるためである.

1. 畳み込み層
1. 全結合層

正解：1

-------

問96

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

畳み込みニューラルネットワークの（ア）のパラメータ数は（イ）と比較して極めて少ない.これは（ウ）によって（エ）ため,パラメータ数が減り,計算量が少なくなるためである.

1. 畳み込み層
1. 全結合層

正解：2

-------

問97

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

畳み込みニューラルネットワークの（ア）のパラメータ数は（イ）と比較して極めて少ない.これは（ウ）によって（エ）ため,パラメータ数が減り,計算量が少なくなるためである.

1. 重み共有
1. 事前学習
1. ランダムサンプリング
1. ドロップアウト

正解：1

-------

問98

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

畳み込みニューラルネットワークの（ア）のパラメータ数は（イ）と比較して極めて少ない.これは（ウ）によって（エ）ため,パラメータ数が減り,計算量が少なくなるためである.

1. 有用な特徴量を画像の位置によって大きく変化させない
1. 学習時間を短縮させる
1. モデルを運用した際に示す性能を見積もる
1. 訓練データだけに過剰に適合することを避ける

正解：1

-------

問99

人工知能が進化するにつれ,人々の生活が格段に豊かになることが期待される一方で,悪用や乱用で公共の利益を損なう可能性も否定できない.人工知能という高度な専門的職業に従事するものとして,その社会における責任を自覚し,社会と対話をしていく行動が必要となる.一般社団法人人工知能学会は,9 つの指針を定めた.選択肢から,この指針に含まれるものを 1 つ選べ.

1. 人類への貢献
1. 法規制の遵守
1. 他者のプライバシーの尊重
1. 上記のすべて

正解：4

-------

問100

人工知能の急激な進化により,様々なことが言われている.一つは,人工知能によって人類が危機にさらされるのではないかという議論である.2014 年のテレビインタビューにおいて「人工知能の進化は人類の終焉を意味する」と発言したのは以下の誰か.

1. イーロン・マスク（テスラ社長）
1. スティーブン・ホーキング（宇宙物理学博士）
1. ビル・ゲイツ（マイクロソフト創業者）
1. ニック・ボストロム（哲学者）

正解：2

-------

問101

1980 年代に登場し,特定領域に限り実用的成果をあげた AI の研究に関して,適切な選択肢を 1 つ選べ.

1. セマンティックウェブ
1. エキスパートシステム
1. オントロジー
1. マルチエージェント

正解：2

-------

問102

Facebook 社が招いたディープラーニングの研究者として,正しい人物を選択肢から 1 つ選べ.

1. Andrew Ng
1. Yann LeCun
1. Geoffrey Hinton
1. Terry Winograd

正解：2

-------

問103

1950 年代頃よりコンピューターの使用が開始されると,計算だけでなく思考機械の研究が始まった.人工知能研究の変遷として,適切な選択肢を 1 つ選べ.

1. パターン処理 -> 記号処理 -> 知識の蓄積
1. 記号処理 -> 知識の蓄積 -> パターン処理
1. 知識の蓄積 -> 記号処理 -> パターン処理

正解：1

-------

問104

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

現在,人工知能研究は抽象概念や知識理解に辿り着くために大きく分けて三つの路線を辿っている.この三つの路線は,とりわけある企業や大学によって研究が進められている.
・言語データによる RNN や映像データからの概念・知識理解を目指す（ア）路線
・実世界を対象に研究を進め,知識理解を目指す（イ）路線
・オンライン空間上でできることをターゲットにするして,知識理解を目指す（ウ）路線

1. UC Berkeley
1. DeepMind 社
1. Google 社・Facebook 社
1. Twitter 社・Amazon 社

正解：3

-------

問105

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

現在,人工知能研究は抽象概念や知識理解に辿り着くために大きく分けて三つの路線を辿っている.この三つの路線は,とりわけある企業や大学によって研究が進められている.
・言語データによる RNN や映像データからの概念・知識理解を目指す（ア）路線
・実世界を対象に研究を進め,知識理解を目指す（イ）路線
・オンライン空間上でできることをターゲットにするして,知識理解を目指す（ウ）路線

1. UC Berkeley
1. DeepMind 社
1. Google 社・Facebook 社
1. Twitter 社・Amazon 社

正解：1

-------

問106

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

現在,人工知能研究は抽象概念や知識理解に辿り着くために大きく分けて三つの路線を辿っている.この三つの路線は,とりわけある企業や大学によって研究が進められている.
・言語データによる RNN や映像データからの概念・知識理解を目指す（ア）路線
・実世界を対象に研究を進め,知識理解を目指す（イ）路線
・オンライン空間上でできることをターゲットにするして,知識理解を目指す（ウ）路線

1. UC Berkeley
1. DeepMind 社
1. Google 社・Facebook 社
1. Twitter 社・Amazon 社

正解：2

-------

問107

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

（ア）はデータに潜む空間的構造をモデル化する.（イ）は時間的構造をモデル化する.

1. CNN
1. RNN
1. DQN
1. DNN

正解：1

-------

問108

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

（ア）はデータに潜む空間的構造をモデル化する.（イ）は時間的構造をモデル化する.

1. CNN
1. RNN
1. DQN
1. DNN

正解：2

-------

問109

次の（ア）,（イ）,（ウ）の組み合わせとして,適切な選択肢を 1 つ選べ.

人間の脳における学習の枠組みに基づいた三つの学習が機械学習には存在する.一つ目は小脳の働きを模倣した（ア）である.これは学習者に対して,教師が間違いを指摘し,学習者が正しい解を得ることである.二つ 目は大脳皮質の働きを模倣した（イ）である.代表的な手法として主成分分析（PCA）などの次元圧縮手法がある.三つ目は大脳基底核の働きを模倣した（ウ）である.学習者は正解値でなく,行動した結果に基づいた報酬が与えられる.この報酬をなるべく大きくするように学習者が行動していく.

1. ア: 強化学習, イ: 教師あり学習, ウ: 教師なし学習
1. ア: 教師あり学習, イ: 強化学習, ウ: 教師なし学習
1. ア: 教師なし学習, イ: 教師あり学習, ウ: 強化学習
1. ア: 教師あり学習, イ: 教師なし学習, ウ: 強化学習

正解：4

-------

問110

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

狭い意味でのディープラーニングとは層の数が深いニューラルネットワークを用いた機械学習である.複数の層を持つ階層的ニューラルネットワークは,1980 年代には（ア）という方法がすでに提案されていたが,現在ほど多くの層を持った学習をすることはできなかった.その理由として二つの理由が挙げられる.一つ目は,出力層における誤差を入力層に向けて伝播させる間に,誤差情報が徐々に拡散し,入力層に近い層では勾配の値が小さくなって学習がうまく進まないとい問題が発生したからだ.このことを（イ）という.二つ目は,層の数が多いニューラルネットワークの学習の目的関数は多くの（ウ）を持ち,適切な結合の重みの初期値の設定が難しかった.

1. パーセプトロン
1. エキスパートシステム
1. 畳み込みニューラルネットワーク
1. 誤差逆伝播学習

正解：4

-------

問111

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

狭い意味でのディープラーニングとは層の数が深いニューラルネットワークを用いた機械学習である.複数の層を持つ階層的ニューラルネットワークは,1980 年代には（ア）という方法がすでに提案されていたが,現在ほど多くの層を持った学習をすることはできなかった.その理由として二つの理由が挙げられる.一つ目は,出力層における誤差を入力層に向けて伝播させる間に,誤差情報が徐々に拡散し,入力層に近い層では勾配の値が小さくなって学習がうまく進まないとい問題が発生したからだ.このことを（イ）という.二つ目は,層の数が多いニューラルネットワークの学習の目的関数は多くの（ウ）を持ち,適切な結合の重みの初期値の設定が難しかった.

1. 学習停止現象
1. 勾配消失現象
1. 過学習
1. 線形分離不可

正解：2

-------

問112

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

狭い意味でのディープラーニングとは層の数が深いニューラルネットワークを用いた機械学習である.複数の層を持つ階層的ニューラルネットワークは,1980 年代には（ア）という方法がすでに提案されていたが,現在ほど多くの層を持った学習をすることはできなかった.その理由として二つの理由が挙げられる.一つ目は,出力層における誤差を入力層に向けて伝播させる間に,誤差情報が徐々に拡散し,入力層に近い層では勾配の値が小さくなって学習がうまく進まないとい問題が発生したからだ.このことを（イ）という.二つ目は,層の数が多いニューラルネットワークの学習の目的関数は多くの（ウ）を持ち,適切な結合の重みの初期値の設定が難しかった.

1. 最頻値
1. 最小値
1. 平均値
1. 極小値

正解：4

-------

問113

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

現在の教師あり学習は,与えられたデータがどの分類に当てはまるのかを識別する（ア）と,様々な関連性のある過去の数値から未知の数値を予測する（イ）という二つに分類される.（ア）を用いることで,（ウ）のようなことができる.また（イ）を用いることで,（エ）のようなことができる.

1. 回帰
1. クラス分類
1. クラスタリング
1. 次元削減

正解：2

-------

問114

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

現在の教師あり学習は,与えられたデータがどの分類に当てはまるのかを識別する（ア）と,様々な関連性のある過去の数値から未知の数値を予測する（イ）という二つに分類される.（ア）を用いることで,（ウ）のようなことができる.また（イ）を用いることで,（エ）のようなことができる.

1. 回帰
1. クラス分類
1. クラスタリング
1. 次元削減

正解：1

-------

問115

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

現在の教師あり学習は,与えられたデータがどの分類に当てはまるのかを識別する（ア）と,様々な関連性のある過去の数値から未知の数値を予測する（イ）という二つに分類される.（ア）を用いることで,（ウ）のようなことができる.また（イ）を用いることで,（エ）のようなことができる.

1. 画像の識別
1. 降水確率の予測
1. 株価の予測
1. ロボットの自立歩行

正解：1

-------

問116

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

現在の教師あり学習は,与えられたデータがどの分類に当てはまるのかを識別する（ア）と,様々な関連性のある過去の数値から未知の数値を予測する（イ）という二つに分類される.（ア）を用いることで,（ウ）のようなことができる.また（イ）を用いることで,（エ）のようなことができる.

1. メールのスパム判定
1. 顧客のグルーピング
1. 売上の予測
1. 音楽のジャンル判定

正解：3

-------

問117

表現学習とは,ディープラーニングを抽象化した概念で,画像,音,自然言語などの要素を,予問題として解くことで分散表現（ベクトル）を得て,各々の要素を抽象化する手法である.こうした特徴表現は,通常は人間の知識によって定義されるが,それによって機械学習の性能が大きく異なってしまう.こうした知的な情報処理を可能にしたのがディープラーニングである.ディープラーニングは観測データの説明要因を捉え,人間の知識では気がつくことができない共通点を捉えることができるが,この共通点のことをよい表現という.「ディープラーニングの父」の一人と言われるヨシュア・ベンジオは良い表現に共通する,世界に関する多くの一般的な事前知識として,いくつかを提唱している.よい表現として当てはまらないものを選択肢から 1 つ選べ.

1. 複数の説明変数の存在
1. 目的変数の階層的構造
1. 時間的空間的一貫性
1. スパース性

正解：2

-------

問118

空欄（ア）,（イ）,（ウ）の組み合わせとして,適切な選択肢を 1 つ選べ.

良い表現として,ディープラーニングのアプローチは（ア）, （イ）,（ウ）に着目している.このことから,（ア）,（イ）,（ウ）の事前知識を適切に活用できるなら,表現学習は必ずしも層の数が多いニューラルネットワークの形をしていなくてもよいことになる.

1. ・説明要因の階層的構造・タスク間の共通要因・自然なクラスタ化
1. ・説明要因の階層的構造・タスク間の共通要因・要因の依存の単純性
1. ・タスク間の共通要因・要因の依存性の単純性・時間的空間的一貫性
1. ・タスク間の共通要因・自然なクラスタ化・時間的空間的一貫性

正解：2

-------

問119

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

教師なし学習の中で有名なものとして,未知の集合をいくつかの集まりに分類させる（ア）という学習方法と,正常な行為がどのようなものかを学習し,それと大きく異なるものを識別する（イ）がある.（ア）は特に（ウ）というアルゴリズムを使用して顧客の分類分けによる DM 配信やレコメンドを行うシステムなどに使用されている.（イ）は（エ）というアルゴリズムを基に,セキュリティシステムなどに使用されている.

1. ホワイトニング
1. クラスタリング
1. バギング
1. ブースティング

正解：2

-------

問120

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

教師なし学習の中で有名なものとして,未知の集合をいくつかの集まりに分類させる（ア）という学習方法と,正常な行為がどのようなものかを学習し,それと大きく異なるものを識別する（イ）がある.（ア）は特に（ウ）というアルゴリズムを使用して顧客の分類分けによる DM 配信やレコメンドを行うシステムなどに使用されている.（イ）は（エ）というアルゴリズムを基に,セキュリティシステムなどに使用されている.

1. 局所検知
1. 欠損検知
1. 異常検知
1. 平均検知

正解：3

-------

問121

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

教師なし学習の中で有名なものとして,未知の集合をいくつかの集まりに分類させる（ア）という学習方法と,正常な行為がどのようなものかを学習し,それと大きく異なるものを識別する（イ）がある.（ア）は特に（ウ）というアルゴリズムを使用して顧客の分類分けによる DM 配信やレコメンドを行うシステムなどに使用されている.（イ）は（エ）というアルゴリズムを基に,セキュリティシステムなどに使用されている.

1. K-nearest neighbor
1. N-gram
1. T-test
1. K-means

正解：4

-------

問122

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

教師なし学習の中で有名なものとして,未知の集合をいくつかの集まりに分類させる（ア）という学習方法と,正常な行為がどのようなものかを学習し,それと大きく異なるものを識別する（イ）がある.（ア）は特に（ウ）というアルゴリズムを使用して顧客の分類分けによる DM 配信やレコメンドを行うシステムなどに使用されている.（イ）は（エ）というアルゴリズムを基に,セキュリティシステムなどに使用されている.

1. ベイズ線形回帰
1. ランダムフォレスト
1. SVM
1. 主成分回帰

正解：3

-------

問123

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

画像の認識では,主に入力から出力に向かう結合のみを持つ階層的なニューラルネットワーク,特に画像などの信号に内在する局所的な特徴が集まって,より大域的な特徴を構成するという構造を反映した,（ア）がよく用いられる.一方,自然言語テキストや動画に代表される構造を持った系列情報を扱うために（イ）が用いられている.特にケプラー大学のゼップ・ホフレイターの提案した（ウ）は必要な文脈情報の長さを適応的に制御することで,時間を遡る誤差逆伝播の可能性を向上させ,画像からの説明文の生成や機械翻訳など,多くの課題に適用されている.実際,2016 年秋に,google 社は google 翻訳に（ウ）を取り入れてアップデートし,非常に高精度な翻訳を提供することが可能になった.

1. DQN
1. MLP
1. RNN
1. CNN

正解：4

-------

問124

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

画像の認識では,主に入力から出力に向かう結合のみを持つ階層的なニューラルネットワーク,特に画像などの信号に内在する局所的な特徴が集まって,より大域的な特徴を構成するという構造を反映した,（ア）がよく用いられる.一方,自然言語テキストや動画に代表される構造を持った系列情報を扱うために（イ）が用いられている.特にケプラー大学のゼップ・ホフレイターの提案した（ウ）は必要な文脈情報の長さを適応的に制御することで,時間を遡る誤差逆伝播の可能性を向上させ,画像からの説明文の生成や機械翻訳など,多くの課題に適用されている.実際,2016 年秋に,google 社社は google 翻訳に（ウ）を取り入れてアップデートし,非常に高精度な翻訳を提供することが可能になった.

1. DQN
1. MLP
1. RNN
1. CNN

正解：3

-------

問125

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

画像の認識では,主に入力から出力に向かう結合のみを持つ階層的なニューラルネットワーク,特に画像などの信号に内在する局所的な特徴が集まって,より大域的な特徴を構成するという構造を反映した,（ア）がよく用いられる.一方,自然言語テキストや動画に代表される構造を持った系列情報を扱うために（イ）が用いられている.特に現代人工知能（AI）の父として知られているユルゲン・シュミットフーバーとケプラー大学のゼップ・ホフレイターの提案した（ウ）は必要な文脈情報の長さを適応的に制御することで,時間を遡る誤差逆伝播の可能性を向上させ,画像からの説明文の生成や機械翻訳など,多くの課題に適用されている.実際,2016 年秋に,google 社は google 翻訳に（ウ）を取り入れてアップデートし,非常に高精度な翻訳を提供することが可能になった.

1. CTC
1. VGGNet
1. DQN
1. LSTM

正解：4

-------

問126

2012 年に開催された一般物体認識のコンテスト ILSVRC（ImageNet Large Scale Visual Recognition Challenge）において,深い構造を持つ CNN が,従来手法の分類性能を大幅に上回って以来,ディープラーニングが画像認識に盛んに用いられるようになった.ディープラーニングの画像認識への応用先として正しい組み合わせを選択肢から 1 つ選べ.

1．・音声認識・クラス分類
2．・音声認識・翻訳
3．・線形回帰問題・物体セグメンテーション
4．・クラス分類・物体検出

正解：4

-------

問127

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

クラス分類の領域では,CNN という沢山の層を重ねて,深い階層構造をした手法によって研究が進められていて,従来の手法よりも精度の高い認識や分類が可能となった.しかし,沢山の層を重ねた結果,学習に用いられるパラメータの数が膨大となり,学習が上手く進まないとい問題が生じていた.そ問題を解決するために提案されたのが（ア）である.（ア）は,入力層から出力層まで伝播する値と入力層の値を足し合わせたモデルで,この方法によって,入力層まで,勾配値がきちんと伝わり,今では 1000 層といったかなり深い構造でも学習が可能となった.実際,2015 年の ILSVRC で（ア）は人間の成績を上回る成果をあげている

1．DCGAN
2．GAN
3．ResNet
4．FCN

正解：3

-------

問128

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

物体検出とは（ア）である.一方物体セグメンテーションとは（イ）である.

1．対象としている画像のそのものが何かを推定するタスク
2．対象物がどこにあるかをボックスに切り取り,対象物を推定するタスク
3．対象物体と背景をピクセルごとに詳細に切り分けて,そのピクセルごとが示す意味を推定するタスク
4．ある入力値を入力したときに,その入力に基づいて画像を生成するタスク

正解：2

【解説】  
物体検出で有名なアルゴリズムは,2014年に考案されたR-CNN,2015に考案されたFaster R-CNN,2016年に 考案されたYOLOで,全てのアルゴリCNNの技術が内部で使用されている.

-------

問129

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

物体検出とは（ア）である.一方物体セグメンテーションとは（イ）である.

1．対象としている画像のそのものが何かを推定するタスク
2．対象物がどこにあるかをボックスに切り分けて,対象物を推定するタスク
3．対象物体と背景をピクセルごとに詳細に切り分けて,そのピクセルごとが示す意味を推定するタスク
4．ある入力値を入力したときに,その入力に基づいて画像を生成するタスク
正解：3

-------

問130

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

画像キャプションとは,ある画像からそこに写っているものの説明を生成する,画像処理と自然言語処理の融合分野である.キャプションは,対象となる画像を（ア）に入力し,そこから得られた特徴を（イ）に入力することで生成することが可能である.

1．DNN
2．LSTM
3．CNN
4．DQN

正解：3

-------

問131

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

画像キャプションとは,ある画像からそこに写っているものの説明を生成する,画像処理と自然言語処理の融合分野である.キャプションは,対象となる画像を（ア）に入力し,そこから得られた特徴を（イ）に入力することで生成することが可能である.

1. DNN
1. LSTM
1. CNN
1. DQN

正解：2

-------

問132

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

画像生成とは,何もない状態,もしくはある入力値に応じて目標の画像を生成する技術である.今最も利用されている画像生成手法は,GAN という生成敵対ネットワークである.特に,あるランダムな数値の入力値をもとに画像生成を行う DC（ア）やある文章から画像を生成する Attention（ア）などが有名である.このネットワークは（イ）と（ウ）から構成されており,（イ）は（エ）を騙すような画像を出力し,（ウ）は（イ）から出力された画像と本物の画像とを分類するようにそれぞれ学習する.このように学習することで,（イ）は適切な画像を出力することが可能となる.

1. GAN
1. RNN
1. CNN
1. DAN

正解：1

-------

問133

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

画像生成とは,何もない状態,もしくはある入力値に応じて目標の画像を生成する技術である.今最も利用されている画像生成手法は,GAN という生成敵対ネットワークである.特に,あるランダムな数値の入力値をもとに画像生成を行う DC（ア）やある文章から画像を生成する Attention（ア）などが有名である.このネットワークは（イ）と（ウ）から構成されており,（イ）は（エ）を騙すような画像を出力し,（ウ）は（イ）から出力された画像と本物の画像とを分類するようにそれぞれ学習する.このように学習することで,（イ）は適切な画像を出力することが可能となる.

1. 画像識別器
1. 画像生成器
1. 画像分類器

正解：2

-------

問134

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

画像生成とは,何もない状態,もしくはある入力値に応じて目標の画像を生成する技術である.今最も利用されている画像生成手法は,GAN という生成敵対ネットワークである.特に,あるランダムな数値の入力値をもとに画像生成を行う DC（ア）やある文章から画像を生成する Attention（ア）などが有名である.このネットワークは（イ）と（ウ）から構成されており,（イ）は（エ）を騙すような画像を出力し,（ウ）は（イ）から出力された画像と本物の画像とを分類するようにそれぞれ学習する.このように学習することで,（イ）は適切な画像を出力することが可能となる.

1. 画像識別器
1. 画像生成器
1. 画像分類器

正解：1

-------

問135

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

画像生成とは,何もない状態,もしくはある入力値に応じて目標の画像を生成する技術である.今最も利用されている画像生成手法は,GAN という生成敵対ネットワークである.特に,あるランダムな数値の入力値をもとに画像生成を行う DC（ア）やある文章から画像を生成する Attention（ア）などが有名である.このネットワークは（イ）と（ウ）から構成されており,（イ）は（エ）を騙すような画像を出力し,（ウ）は（イ）から出力された画像と本物の画像とを分類するようにそれぞれ学習する.このように学習することで,（イ）は適切な画像を出力することが可能となる.

1. 画像識別器
1. 画像生成器
1. 画像分類器

正解：3

-------

問136

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

従来は,現在のディープラーニングのように入力から出力までの処理を一括で行うことができない情報を扱うことがあった.そうした場合,まず用意したデータをある手法を用いて加工し,それが入力値となり,別の手法を用いて処理を行いといった,ステップバイステップの学習が必要だった.しかし,ディープラーニングの登場によって,処理を複数回に分けて行う必要がなくなったこのような,ディープラーニングにおいて重要な方法論のことを（ア）と呼ぶ.

1. Edge to Edge Learning
1. Bottom to Top Learning
1. Corner to Corner Learning
1. End to End Learning

正解：4

【解説】  
正解は4である.
具体的な例として,音声認識処理が該当する.
ディープラーニング登場前における手法においては
音声波形から音素を分類,音素から文字を分類,文字列から単語を予測し,単語から単語列を予測・出力していた.
ディープラーニングにおいては,音声波形を入力し,単語列を出力
することが可能となった.
End-to-Endという表現は,最初の入力と最終の出力までを一括で,という意味合いである.

選択肢1～3に該当する用語はない.

-------

問137

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

1990 年代の音声認識は（ア）による,音自体を判別するための音響モデルと,（イ）による語と語のつながりを判別する言語モデルの両方でできている.しかし,ディープラーニングの登場,とりわけ（ウ）の登場により,音響特徴量から音素,文字列,更には単語列に直接変換する End to End モデルというアプローチを取ることが可能になり,人的に前処理を行わなくても解析することが可能となった.

1. N グラム法
1. 隠れマルコフモデル（HMM）
1. RNN

正解：2

-------

問138

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

1990 年代の音声認識は（ア）による,音自体を判別するための音響モデルと,（イ）による語と語のつながりを判別する言語モデルの両方でできている.しかし,ディープラーニングの登場,とりわけ（ウ）の登場により,音響特徴量から音素,文字列,更には単語列に直接変換する End to End モデルというアプローチを取ることが可能になり,人的に前処理を行わなくても解析することが可能となった.

1. N グラム法
1. 隠れマルコフモデル（HMM）
1. RNN

正解：1

-------

問139

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

1990 年代の音声認識は（ア）による,音自体を判別するための音響モデルと,（イ）による語と語のつながりを判別する言語モデルの両方でできている.しかし,ディープラーニングの登場,とりわけ（ウ）の登場により,音響特徴量から音素,文字列,更には単語列に直接変換する End to End モデルというアプローチを取ることが可能になり,人的に前処理を行わなくても解析することが可能となった.

1. N グラム法
1. 隠れマルコフモデル（HMM）
1. RNN

正解：3

-------

問140

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングはソフトウェアフレームワークを利用して実装するのが一般的である.多層のニューラルネットワークモデルを定義し,データを用いて学習・予測を実行するのがフレームワークの役割だが,重要なのはネットワークの記述方法とその柔軟性である.ネットワークには大きく分けて 二つの記述方法がある.一つ目は（ア）による記述方法である.これらの記述方法を採用しているソフトウェアには（イ）があげられる.この方法を用いることによって,モデルの定義がテキストで設定でき,簡単に学習を開始させることが出来るというメリットがある.一方で,ループ構造をもつような RNN など,複雑なモデルを扱う際には,モデルの定義を記述することは難しくなる傾向にある.二つ目は（ウ）による記述方法である.代表的なフレームワークとして（エ）があげられる.一度書き方を覚えてしまえば,複雑なモデルでも比較的簡単に記述することが出来るが,モデルは,それぞれのフレームワーク固有のソースコードで出来上がるため,モデルが使用しているソフトウェアに依存してしまうとい問題がある.

1. プログラム
1. 設定ファイル
1. バッチファイル
1. 実行ファイル

正解：2

-------

問141

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングはソフトウェアフレームワークを利用して実装するのが一般的である.多層のニューラルネットワークモデルを定義し,データを用いて学習・予測を実行するのがフレームワークの役割だが,重要なのはネットワークの記述方法とその柔軟性である.ネットワークには大きく分けて 二つの記述方法がある.一つ目は（ア）による記述方法である.これらの記述方法を採用しているソフトウェアには（イ）があげられる.この方法を用いることによって,モデルの定義がテキストで設定でき,簡単に学習を開始させることが出来るというメリットがある.一方で,ループ構造をもつような RNN など,複雑なモデルを扱う際には,モデルの定義を記述することは難しくなる傾向にある.二つ目は（ウ）による記述方法である.代表的なフレームワークとして（エ）があげられる.一度書き方を覚えてしまえば,複雑なモデルでも比較的簡単に記述することが出来るが,モデルは,それぞれのフレームワーク固有のソースコードで出来上がるため,モデルが使用しているソフトウェアに依存してしまうとい問題がある.

1. Caffe やChainer
1. TensorFlow やChainer
1. Caffe やCNTK
1. TensorFlow やCNTK

正解：3

-------

問142

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングはソフトウェアフレームワークを利用して実装するのが一般的である.多層のニューラルネットワークモデルを定義し,データを用いて学習・予測を実行するのがフレームワークの役割だが,重要なのはネットワークの記述方法とその柔軟性である.ネットワークには大きく分けて 二つの記述方法がある.一つ目は（ア）による記述方法である.これらの記述方法を採用しているソフトウェアには（イ）があげられる.この方法を用いることによって,モデルの定義がテキストで設定でき,簡単に学習を開始させることが出来るというメリットがある.一方で,ループ構造をもつような RNN など,複雑なモデルを扱う際には,モデルの定義を記述することは難しくなる傾向にある.二つ目は（ウ）による記述方法である.代表的なフレームワークとして（エ）があげられる.一度書き方を覚えてしまえば,複雑なモデルでも比較的簡単に記述することが出来るが,モデルは,それぞれのフレームワーク固有のソースコードで出来上がるため,モデルが使用しているソフトウェアに依存してしまうとい問題がある.

1. プログラム
1. 設定ファイル
1. バッチファイル
1. 実行ファイル

正解：1

-------

問143

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングはソフトウェアフレームワークを利用して実装するのが一般的である.多層のニューラルネットワークモデルを定義し,データを用いて学習・予測を実行するのがフレームワークの役割だが,重要なのはネットワークの記述方法とその柔軟性である.ネットワークには大きく分けて 二つの記述方法がある.一つ目は（ア）による記述方法である.これらの記述方法を採用しているソフトウェアには（イ）があげられる.この方法を用いることによって,モデルの定義がテキストで設定でき,簡単に学習を開始させることが出来るというメリットがある.一方で,ループ構造をもつような RNN など,複雑なモデルを扱う際には,モデルの定義を記述することは難しくなる傾向にある.二つ目は（ウ）による記述方法である.代表的なフレームワークとして（エ）があげられる.一度書き方を覚えてしまえば,複雑なモデルでも比較的簡単に記述することが出来るが,モデルは,それぞれのフレームワーク固有のソースコードで出来上がるため,モデルが使用しているソフトウェアに依存してしまうとい問題がある.

1. Caffe や Chainer
1. TensorFlow や Chainer
1. Caffe や CNTK
1. TensorFlow や CNTK

正解：2

-------

問144

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

線形モデルとは,（ア）を含む項の線形結合で,（ア）を含んだ数式の出力値は（イ）と呼ばれる.この線形結合で,特に（ア）も（イ）も一次元のデータの場合は,y = b0 + b1 * x と表される.こういったモデルを単回帰モデルと呼んだりもする.この数式において,各項の係数（例えば b0, b1）を（ウ）と呼び,このモデルを用いてテストデータを学習し,測定した実データを推定する.注意点として,（イ）が連続の値を取り扱う場合（エ）と呼ばれるが,離散の値を取り扱われる場合は（オ）と呼ばれ,それぞれ名称が異なる.ただ,実際のデータを扱うときに,（ア）が 1 次元であることはほとんどなく,2 次元以上になることが一般的である.このような場合,（ア）の次元数分だけ,係数パラメータを増やして,モデルを拡張する必要がある.このように（ア）が 2 つ以上の場合を（カ）モデルと呼び,各項の係数パラメータを（キ）という.またモデルによって出力された値と実際の測定値の誤差を（ク）という.この（ク）を用いて係数パラメータを推定する代表的なアルゴリズムに最小二乗法と最尤推定法がある.

1. 被説明変数
1. 相関係数
1. バイアス
1. 説明変数

正解：4

-------

問145

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

線形モデルとは,（ア）を含む項の線形結合で,（ア）を含んだ数式の出力値は（イ）と呼ばれる.この線形結合で,特に（ア）も（イ）も一次元のデータの場合は,y = b0 + b1 * x と表される.こういったモデルを単回帰モデルと呼んだりもする.この数式において,各項の係数（例えば b0, b1）を（ウ）と呼び,このモデルを用いてテストデータを学習し,測定した実データを推定する.注意点として,（イ）が連続の値を取り扱う場合（エ）と呼ばれるが,離散の値を取り扱われる場合は（オ）と呼ばれ,それぞれ名称が異なる.ただ,実際のデータを扱うときに,（ア）が 1 次元であることはほとんどなく,2 次元以上になることが一般的である.このような場合,（ア）の次元数分だけ,係数パラメータを増やして,モデルを拡張する必要がある.このように（ア）が 2 つ以上の場合を（カ）モデルと呼び,各項の係数パラメータを（キ）という.またモデルによって出力された値と実際の測定値の誤差を（ク）という.この（ク）を用いて係数パラメータを推定する代表的なアルゴリズムに最小二乗法と最尤推定法がある.

1. 被説明変数
1. 相関係数
1. バイアス
1. 説明変数

正解：1

-------

問146

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

線形モデルとは,（ア）を含む項の線形結合で,（ア）を含んだ数式の出力値は（イ）と呼ばれる.この線形結合で,特に（ア）も（イ）も一次元のデータの場合は,y = b0 + b1 * x と表される.こういったモデルを単回帰モデルと呼んだりもする.この数式において,各項の係数（例えば b0, b1）を（ウ）と呼び,このモデルを用いてテストデータを学習し,測定した実データを推定する.注意点として,（イ）が連続の値を取り扱う場合（エ）と呼ばれるが,離散の値を取り扱われる場合は（オ）と呼ばれ,それぞれ名称が異なる.ただ,実際のデータを扱うときに,（ア）が 1 次元であることはほとんどなく,2 次元以上になることが一般的である.このような場合,（ア）の次元数分だけ,係数パラメータを増やして,モデルを拡張する必要がある.このように（ア）が 2 つ以上の場合を（カ）モデルと呼び,各項の係数パラメータを（キ）という.またモデルによって出力された値と実際の測定値の誤差を（ク）という.この（ク）を用いて係数パラメータを推定する代表的なアルゴリズムに最小二乗法と最尤推定法がある.

1. パラメータ
1. ハイパーパラメータ
1. 傾き
1. 切片

正解：1

-------

問147

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

線形モデルとは,（ア）を含む項の線形結合で,（ア）を含んだ数式の出力値は（イ）と呼ばれる.この線形結合で,特に（ア）も（イ）も一次元のデータの場合は,y = b0 + b1 * x と表される.こういったモデルを単回帰モデルと呼んだりもする.この数式において,各項の係数（例えば b0, b1）を（ウ）と呼び,このモデルを用いてテストデータを学習し,測定した実データを推定する.注意点として,（イ）が連続の値を取り扱う場合（エ）と呼ばれるが,離散の値を取り扱われる場合は（オ）と呼ばれ,それぞれ名称が異なる.ただ,実際のデータを扱うときに,（ア）が 1 次元であることはほとんどなく,2 次元以上になることが一般的である.このような場合,（ア）の次元数分だけ,係数パラメータを増やして,モデルを拡張する必要がある.このように（ア）が 2 つ以上の場合を（カ）モデルと呼び,各項の係数パラメータを（キ）という.またモデルによって出力された値と実際の測定値の誤差を（ク）という.この（ク）を用いて係数パラメータを推定する代表的なアルゴリズムに最小二乗法と最尤推定法がある.

1. 回帰
1. 分類

正解：1

-------

問148

（オ）に最もよくあてはまる選択肢を 1 つ選べ.

線形モデルとは,（ア）を含む項の線形結合で,（ア）を含んだ数式の出力値は（イ）と呼ばれる.この線形結合で,特に（ア）も（イ）も一次元のデータの場合は,y = b0 + b1 * x と表される.こういったモデルを単回帰モデルと呼んだりもする.この数式において,各項の係数（例えば b0, b1）を（ウ）と呼び,このモデルを用いてテストデータを学習し,測定した実データを推定する.注意点として,（イ）が連続の値を取り扱う場合（エ）と呼ばれるが,離散の値を取り扱われる場合は（オ）と呼ばれ,それぞれ名称が異なる.ただ,実際のデータを扱うときに,（ア）が 1 次元であることはほとんどなく,2 次元以上になることが一般的である.このような場合,（ア）の次元数分だけ,係数パラメータを増やして,モデルを拡張する必要がある.このように（ア）が 2 つ以上の場合を（カ）モデルと呼び,各項の係数パラメータを（キ）という.またモデルによって出力された値と実際の測定値の誤差を（ク）という.この（ク）を用いて係数パラメータを推定する代表的なアルゴリズムに最小二乗法と最尤推定法がある.

1. 回帰
1. 分類

正解：2

-------

問149

（カ）に最もよくあてはまる選択肢を 1 つ選べ.

線形モデルとは,（ア）を含む項の線形結合で,（ア）を含んだ数式の出力値は（イ）と呼ばれる.この線形結合で,特に（ア）も（イ）も一次元のデータの場合は,y = b0 + b1 * x と表される.こういったモデルを単回帰モデルと呼んだりもする.この数式において,各項の係数（例えば b0, b1）を（ウ）と呼び,このモデルを用いてテストデータを学習し,測定した実データを推定する.注意点として,（イ）が連続の値を取り扱う場合（エ）と呼ばれるが,離散の値を取り扱われる場合は（オ）と呼ばれ,それぞれ名称が異なる.ただ,実際のデータを扱うときに,（ア）が 1 次元であることはほとんどなく,2 次元以上になることが一般的である.このような場合,（ア）の次元数分だけ,係数パラメータを増やして,モデルを拡張する必要がある.このように（ア）が 2 つ以上の場合を（カ）モデルと呼び,各項の係数パラメータを（キ）という.またモデルによって出力された値と実際の測定値の誤差を（ク）という.この（ク）を用いて係数パラメータを推定する代表的なアルゴリズムに最小二乗法と最尤推定法がある.

1. 複回帰
1. 多回帰
1. 重回帰
1. 編回帰

正解：3

-------

問150

（キ）に最もよくあてはまる選択肢を 1 つ選べ.

線形モデルとは,（ア）を含む項の線形結合で,（ア）を含んだ数式の出力値は（イ）と呼ばれる.この線形結合で,特に（ア）も（イ）も一次元のデータの場合は,y = b0 + b1 * x と表される.こういったモデルを単回帰モデルと呼んだりもする.この数式において,各項の係数（例えば b0, b1）を（ウ）と呼び,このモデルを用いてテストデータを学習し,測定した実データを推定する.注意点として,（イ）が連続の値を取り扱う場合（エ）と呼ばれるが,離散の値を取り扱われる場合は（オ）と呼ばれ,それぞれ名称が異なる.ただ,実際のデータを扱うときに,（ア）が 1 次元であることはほとんどなく,2 次元以上になることが一般的である.このような場合,（ア）の次元数分だけ,係数パラメータを増やして,モデルを拡張する必要がある.このように（ア）が 2 つ以上の場合を（カ）モデルと呼び,各項の係数パラメータを（キ）という.またモデルによって出力された値と実際の測定値の誤差を（ク）という.この（ク）を用いて係数パラメータを推定する代表的なアルゴリズムに最小二乗法と最尤推定法がある.

1. 複回帰係数
1. 多回帰係数
1. 重回帰係数
1. 偏回帰係数

正解：4

-------

問151

（ク）に最もよくあてはまる選択肢を 1 つ選べ.

線形モデルとは,（ア）を含む項の線形結合で,（ア）を含んだ数式の出力値は（イ）と呼ばれる.この線形結合で,特に（ア）も（イ）も一次元のデータの場合は,y = b0 + b1 * x と表される.こういったモデルを単回帰モデルと呼んだりもする.この数式において,各項の係数（例えば b0, b1）を（ウ）と呼び,このモデルを用いてテストデータを学習し,測定した実データを推定する.注意点として,（イ）が連続の値を取り扱う場合（エ）と呼ばれるが,離散の値を取り扱われる場合は（オ）と呼ばれ,それぞれ名称が異なる.ただ,実際のデータを扱うときに,（ア）が 1 次元であることはほとんどなく,2 次元以上になることが一般的である.このような場合,（ア）の次元数分だけ,係数パラメータを増やして,モデルを拡張する必要がある.このように（ア）が 2 つ以上の場合を（カ）モデルと呼び,各項の係数パラメータを（キ）という.またモデルによって出力された値と実際の測定値の誤差を（ク）という.この（ク）を用いて係数パラメータを推定する代表的なアルゴリズムに最小二乗法と最尤推定法がある.

1. 残差
1. エラー
1. モデル誤差
1. 余剰

正解：1

-------

問152

最小二乗法の説明として最も適切な選択肢を 1 つ選べ.

1. モデルの予測値と実データの差が最小になるような係数パラメータを求める方法
1. 各クラスの最も近いデータの距離を最大化することで係数パラメータを得る方法
1. ある係数パラメータが与えられたときに,モデルが実データを予測する確率（尤度）を最大化するような係数パラメータを求める方法
1. モデルの予測値と実データの差から損失関数を算出して,それを減少させるようにパラメータを更新させる方法

正解：1

-------

問153

最尤推定法の説明として最も適切な選択肢を 1 つ選べ.

1. モデルの予測値と実データの差が最小になるような係数パラメータを求める方法
1. 各クラスの最も近いデータの距離を最大化することで係数パラメータを得る方法
1. ある係数パラメータが与えられたときに,モデルが実データを予測する確率（尤度）を最大化するような係数パラメータを求める方法
1. モデルの予測値と実データの差から損失関数を算出して,それを減少させるようにパラメータを更新させる方法

正解：3

【解説】  
正解は3である.
選択肢1：最小二乗法のこと.
選択肢2：SVMにおける所謂,マージン最大化のこと.
選択肢3：最尤推定法のこと.
選択肢4：勾配降下法のこと.

-------

問154

最小二乗法の説明として誤った選択肢を 1 つ選べ

1. 答えが常に絶対値になり計算しやすくなる
1. 符号を考えなくてよくなり計算がしやすくなる
1. サンプル中に大きく外れた異常値が混じっている場合,この異常値に線が大きく引っ張られるので異常値を考慮する必要がある

正解：1

-------

問155

ディープラーニングの使用の注意点として,最も適切な選択肢を 1 つ選べ.

1. 高性能は達成できるが,学習に従来以上の大量訓練データが必要になる
1. 判定の結果は人間に理解しやすい
1. データ量が十分でないときでもディープラーニングは高い成果を残すことができる
1. データを分析する際はまずディープラーニングの手法を試してみるとよい

正解：1

-------

問156

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングの学習の目的は,損失関数の値をできるだけ小さくするパラメータを見つけることである.このよう問題を解くことを（ア）という.このパラメータを見つけるアルゴリズムとして有名なのは（イ） である.ただ,（イ）は対象の関数の形がある分布や方向に依存すると非効率な経路でパラメータを探索してしまい,学習に時間がかかってしまうというデメリットがある.そこで,現在では（イ）の欠点を改善するために（ウ） などのアルゴリズムが使用されている.

1. 最適化
1. バリデーション
1. パラメタライズ
1. 局所探索

正解：1

-------

問157

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングの学習の目的は,損失関数の値をできるだけ小さくするパラメータを見つけることである.このよう問題を解くことを（ア）という.このパラメータを見つけるアルゴリズムとして有名なのは（イ） である.ただ,（イ）は対象の関数の形がある分布や方向に依存すると非効率な経路でパラメータを探索してしまい,学習に時間がかかってしまうというデメリットがある.そこで,現在では（イ）の欠点を改善するために（ウ） などのアルゴリズムが使用されている.

1. HMM
1. Sigmoid
1. Relu
1. SGD

正解：4

【解説】  
正解は4である.
選択肢1：隠れマルコフモデルのこと
選択肢2：活性化関数として用いられるシグモイド関数のこと
選択肢3：活性化関数として用いられるRelu関数のこと
選択肢4：確率的勾配降下法のこと

-------

問158

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングの学習の目的は,損失関数の値をできるだけ小さくするパラメータを見つけることである.このよう問題を解くことを（ア）という.このパラメータを見つけるアルゴリズムとして有名なのは（イ） である.ただ,（イ）は対象の関数の形がある分布や方向に依存すると非効率な経路でパラメータを探索してしまい,学習に時間がかかってしまうというデメリットがある.そこで,現在では（イ）の欠点を改善するために（ウ） などのアルゴリズムが使用されている.

1. Adam
1. Relu
1. He
1. Xavier

正解：1

【解説】  
正解は1である.
選択肢1：
-------

問題文のとおりである.
選択肢2：活性化関数として用いられるRelu関数のこと
選択肢3,4：ネットワークのエッジにおける重みの初期値を決定する手法のこと

-------

問159

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

機械が試行錯誤することで,取るべき最善の行動を決定す問題を扱うことができる学習方法を（ア）という.（ア）はボードゲームや自動運転,またロボットの歩行動作などに活用されている.代表的なアルゴリズムに （イ）があげられる.（ア）の課題として,主に（ウ）や（エ）などが挙げられる.理論的には無限に学習するが,実世界では全てが限られている.ロボットの場合,無限の試行を繰り返すことができず,損耗し,実験の続行が困難になる.そこで人間側がタスクを上手く切り分けてやさしいタスクからの学習をすることが期待される.また（エ）に関して,例として,2 体のロボット同士で学習を開始させようとすると,お互いに初期状態であるタスクについての何も知識がない状態だと,学習過程の不安定化が見られる.現在はこれに対応するために逆強化学習やディープラーニングの技術を適用した（オ）などが適用され始めている.

1. オンライン学習
1. アンサンブル学習
1. ミニバッチ学習
1. 強化学習

正解：4

-------

問160

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

機械が試行錯誤することで,取るべき最善の行動を決定す問題を扱うことができる学習方法を（ア）という.（ア）はボードゲームや自動運転,またロボットの歩行動作などに活用されている.代表的なアルゴリズムに （イ）があげられる.（ア）の課題として,主に（ウ）や（エ）などが挙げられる.理論的には無限に学習するが,実世界では全てが限られている.ロボットの場合,無限の試行を繰り返すことができず,損耗し,実験の続行が困難になる.そこで人間側がタスクを上手く切り分けてやさしいタスクからの学習をすることが期待される.また（エ）に関して,例として,2 体のロボット同士で学習を開始させようとすると,お互いに初期状態であるタスクについての何も知識がない状態だと,学習過程の不安定化が見られる.現在はこれに対応するために逆強化学習やディープラーニングの技術を適用した（オ）などが適用され始めている.

1. SVM
1. ブースティング
1. QNN
1. Q学習

正解：4

-------

問161

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

機械が試行錯誤することで,取るべき最善の行動を決定す問題を扱うことができる学習方法を（ア）という.（ア）はボードゲームや自動運転,またロボットの歩行動作などに活用されている.代表的なアルゴリズムに （イ）があげられる.（ア）の課題として,主に（ウ）や（エ）などが挙げられる.理論的には無限に学習するが,実世界では全てが限られている.ロボットの場合,無限の試行を繰り返すことができず,損耗し,実験の続行が困難になる.そこで人間側がタスクを上手く切り分けてやさしいタスクからの学習をすることが期待される.また（エ）に関して,例として,2 体のロボット同士で学習を開始させようとすると,お互いに初期状態であるタスクについての何も知識がない状態だと,学習過程の不安定化が見られる.現在はこれに対応するために逆強化学習やディープラーニングの技術を適用した（オ）などが適用され始めている.

1. 勾配消失
1. 学習時間
1. 未学習
1. 初期値設定

正解：2

-------

問162

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

機械が試行錯誤することで,取るべき最善の行動を決定す問題を扱うことができる学習方法を（ア）という.（ア）はボードゲームや自動運転,またロボットの歩行動作などに活用されている.代表的なアルゴリズムに （イ）があげられる.（ア）の課題として,主に（ウ）や（エ）などが挙げられる.理論的には無限に学習するが,実世界では全てが限られている.ロボットの場合,無限の試行を繰り返すことができず,損耗し,実験の続行が困難になる.そこで人間側がタスクを上手く切り分けてやさしいタスクからの学習をすることが期待される.また（エ）に関して,例として,2 体のロボット同士で学習を開始させようとすると,お互いに初期状態であるタスクについての何も知識がない状態だと,学習過程の不安定化が見られる.現在はこれに対応するために逆強化学習やディープラーニングの技術を適用した（オ）などが適用され始めている.

1. 自己組織化
1. マルチエージェント応用
1. 自己符号化
1. マルチタスク応用

正解：2

-------

問163

（オ）に最もよくあてはまる選択肢を 1 つ選べ.

機械が試行錯誤することで,取るべき最善の行動を決定す問題を扱うことができる学習方法を（ア）という.（ア）はボードゲームや自動運転,またロボットの歩行動作などに活用されている.代表的なアルゴリズムに （イ）があげられる.（ア）の課題として,主に（ウ）や（エ）などが挙げられる.理論的には無限に学習するが,実世界では全てが限られている.ロボットの場合,無限の試行を繰り返すことができず,損耗し,実験の続行が困難になる.そこで人間側がタスクを上手く切り分けてやさしいタスクからの学習をすることが期待される.また（エ）に関して,例として,2 体のロボット同士で学習を開始させようとすると,お互いに初期状態であるタスクについての何も知識がない状態だと,学習過程の不安定化が見られる.現在はこれに対応するために逆強化学習やディープラーニングの技術を適用した（オ）などが適用され始めている.

1. GRU
1. GAN
1. DQN
1. MLP

正解：3

-------

問164

昨今,ディープラーニングを活用した音声認識技術,音声生成技術の向上に伴い,スマートスピーカーが普及しつつある.下記の選択肢のうち,スマートスピーカーの音声アシスタントソフトウェアの名称とその提供元の組み合わせとして正しいものを選択肢から 1 つ選べ.

1. Apple 社- Alexa
1. NTT ドコモ 社- Siri
1. Microsoft 社- Cortana
1. Amazon 社- しゃべってコンシェルジュ

正解：3
（AI白書：p.216-, p.267-）

-------

問165

以下の文章をよく読み,末尾の問に答えよ.

AI の研究開発が進むにつれて,実世界への社会実装で最も期待されている分野の 1 つに自動走行車の開発が挙げられる.現在 AI を用いた自動走行車には,その自動運転導入の程度に応じてレベルづけがなされており,各社でどのように最終的なゴールであるレベル 5 の完全自動走行に近づくかが議論されている.

各レベルにおける自動運転の概要について説明した文章のうち,自動運転レベル 3 に対応しているものを選択肢より 1 つ選べ.

1. 部分運転自動化
1. 条件付き運転自動化
1. 高度運転自動化
1. 運転支援

正解：2
（AI白書：p.232-）

-------

問166

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

自動運転レベル 5 に至るには,2 つのアプローチが存在している.1 つは自動運転レベル 1 から徐々に運転自動化の範囲を広げていくアプローチ,もう 1 つは直接レベル 3 以上の自動運転を目指そうとするものである.この時,前者のレベル 1 から徐々に運転自動化を目指すアプローチを採っているプレイヤーは （ア） などである.他方で,後者の直接レベル 3 以上の運転自動化を目指すアプローチを採っているプレイヤーは大手IT企業である.また後者のアプローチを採る企業として著名なのは,google 社傘下の Waymo 社である.

1. 流通業者
1. 自動車メーカー
1. 大手IT企業

正解：2
（AI白書：p.270-）

-------

問167

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

自動運転レベル5 に至るには,2 つのアプローチが存在している.1 つは自動運転レベル1 から徐々に運転自動化の範囲を広げていくアプローチ,もう1 つは直接レベル3以上の自動運転を目指そうとするものである.この時,前者のレベル1 から徐々に運転自動化を目指すアプローチを採っているプレイヤーは （ア） などである.他方で,後者の直接レベル3以上の運転自動化を目指すアプローチを採っているプレイヤーは （イ） である.また後者のアプローチを採る企業として著名なのは,google 社傘下の （ウ） 社である.

1. 流通業者
1. 自動車メーカー
1. 大手IT企業

正解：3
（AI白書：p.270-）

-------

問168

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

自動運転レベル5 に至るには,2 つのアプローチが存在している.1 つは自動運転レベル1 から徐々に運転自動化の範囲を広げていくアプローチ,もう1 つは直接レベル3以上の自動運転を目指そうとするものである.この時,前者のレベル1 から徐々に運転自動化を目指すアプローチを採っているプレイヤーは （ア） などである.他方で,後者の直接レベル3以上の運転自動化を目指すアプローチを採っているプレイヤーは （イ） である.また後者のアプローチを採る企業として著名なのは,google 社傘下の （ウ） 社である.

1. Whatsapp
1. Paymo
1. Waybo
1. Waymo

正解：4
（AI白書：p.270-）

-------

問169

以下の文章をよく読み,末尾の問に答えよ.

AI 技術の進展により一般に普及する可能性が急激に高まってきたのが,小型無人機 （以下ドローン） である.他方でこれまでに存在しなかった新しいプロダクトで,人々がこれまで意識することのなかった空域など問題が生じてきた.例えば,ドローンを飛ばす空域は,飛ばすのに許可が必要な空域がある.

選択肢のうち,ドローンを飛ばすのに許可を必要とする空域の説明として正しくないものを選択肢より 1 つ選べ.

1. 電波塔が張り巡らされている地域/ヒト・モノから 15m 以内の飛行の禁止
1. 150m 以上の高さの空域/物の投下の禁止
1. 人口集中地区の上空/イベントなど大勢の人が集まる場所での飛行の禁止
1. 空港等の周辺の上空/ヒト・モノから 15m 以内の飛行の禁止
5.電波塔が張り巡らされている地域/夜間飛行の禁止

正解：1
（AI白書：p.381-）

-------

問170

以下の文章をよく読み,末尾の問に答えよ.

AI 技術の進展により一般に普及する可能性が急激に高まってきたのが,小型無人機 （以下ドローン） である.他方でこれまでに存在しなかった新しいプロダクトで,人々がこれまで意識することのなかった空域など問題が生じてきた.例えば,ドローンを飛ばす空域は,飛ばすのに許可が必要な空域がある.またドローンはその利用方法に応じて,承認が必要となることがある.

ドローンの飛行規制について,「正しくないもの」を選択肢から 1 つ選べ.

1. 夜間飛行の禁止
1. イベントなど大勢の人が集まる場所での飛行の禁止
1. ヒト・モノから15m以内の飛行の禁止
1. 物の投下の禁止

正解：3

【解説】  
正しくは,人・ものから30m未満の飛行は承認が必要である
（AI白書：p.381-）

-------

問171

以下の文章をよく読み,末尾の問に答えよ.

AI の社会実装を進めていくにあたり,AI がもたらす倫理的リスクを事前に考慮しておく必要性が近年強く叫ばれている.各国政府はそれに対応すべく様々な取り組みを行っている.
米国政府の例を取ると,米国政府は 2016 年 10 月に "PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE" を発行し,続けさまに同年 "THE NATIONAL ARTIFICIAL INTELLIGENCE RESEARCH and DEVELOPMENT STRATEGIC PLAN" ,そして 2016 年 12 月に発行した "ARTIFICIAL INTELLIGENCE AUTOMATION, AND THE ECONOMY" などで,これから表面化するであろうリスクへの対応策を事前に協議している.
このうち,"PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE" で協議された内容として最も適切なものを 1 つ選べ.

1. AI の普及が最大で 300 万件越えの雇用に影響を与える可能性があることを説いている
1. AI 実務家や学生に対して倫理観が必要であることを主張している
1. 判断結果の理由をユーザーに説明できる AI プログラムを開発することが必要であることを主張した
1. ロボット技術が進展した場合の法律のあり方について協議がなされた

正解：2
（AI白書：p.364, p426）

-------

問172

以下の文章をよく読み,末尾の問に答えよ.

AI の社会実装を進めていくにあたり,AI がもたらす倫理的リスクを事前に考慮しておく必要性が近年強く叫ばれている.各国政府はそれに対応すべく様々な取り組みを行っている.
米国政府の例を取ると,米国政府は 2016 年 10 月に "PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE" を発行し,続けさまに同年 "THE NATIONAL ARTIFICIAL INTELLIGENCE RESEARCH and DEVELOPMENT STRATEGIC PLAN" ,そして 2016 年 12 月に発行した "ARTIFICIAL INTELLIGENCE AUTOMATION, AND THE ECONOMY" などで,これから表面化するであろうリスクへの対応策を事前に協議している.
このうち,"THE NATIONAL ARTIFICIAL INTELLIGENCE RESEARCH and DEVELOPMENT STRATEGIC PLAN"で協議された内容として最も適切なものを 1 つ選べ.

1. AI の普及が最大で 300 万件越えの雇用に影響を与える可能性があることを説いている
1. AI 実務家や学生に対して倫理観が必要であることを主張している
1. 判断結果の理由をユーザーに説明できる AI プログラムを開発することが必要であることを主張した
1. ロボット技術が進展した場合の法律のあり方について協議がなされた

正解：3
（AI白書：p.364, p.426）

-------

問173

以下の文章をよく読み,末尾の問に答えよ.

AI の社会実装を進めていくにあたり,AI がもたらす倫理的リスクを事前に考慮しておく必要性が近年強く叫ばれている.各国政府はそれに対応すべく様々な取り組みを行なっている.
米国政府の例を取ると,米国政府は 2016 年 10 月に "PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE" を発行し,続けさまに同年 "THE NATIONAL ARTIFICIAL INTELLIGENCE RESEARCH and DEVELOPMENT STRATEGIC PLAN" ,そして 2016 年 12 月に発行した "ARTIFICIAL INTELLIGENCE AUTOMATION, AND THE ECONOMY" などで,これから表面化するであろうリスクへの対応策を事前に協議している.
このうち,"ARTIFICIAL INTELLIGENCE AUTOMATION, AND THE ECONOMY" で協議された内容として最も適切なものを 1 つ選べ.

1. AI の普及が最大で 300 万件越えの雇用に影響を与える可能性があることを説いている
1. AI 実務家や学生に対して倫理観が必要であることを主張している
1. 判断結果の理由をユーザーに説明できる AI プログラムを開発することが必要であることを主張した
1. ロボット技術が進展した場合の法律のあり方について協議がなされた

正解：1
（AI白書：p.364, p.426）

-------

問174

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングの活用を進めていく必要性の高まりに対して,日本国内においてはそうした先端 IT 技術に精通した人材不足が懸念されている.
例えば,経済産業省が定めた先端 IT 人材がどのような人材需給状況にあるかの推定によると,2020 年には需給ギャップが広がり人材の不足は （ア） に及ぶと言われている.
こうした人材不足を解消するべく,様々な方法で AI に理解のある人材育成が試みられている.そのような試みの一つとして,MOOCs は期待を寄せられている.著名な例としては,AI 研究の第一人者で,2014 年から 2017 年にかけて Baidu の AI 研究所所長を務めた （イ） が創業した Coursera などは入門から上級まで様々なレベルの AI 講義が開かれており,多くの受講者を惹きつけるに至っている.

1. 480 人
1. 2400 人
1. 1. 8 万人
1. 240 万人

正解：3
（AI白書：p.100）

-------

問175

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングの活用を進めていく必要性の高まりに対して,日本国内においてはそうした先端 IT 技術に精通した人材不足が懸念されている.
例えば,経済産業省が定めた先端 IT 人材がどのような人材需給状況にあるかの推定によると,2020 年には需給ギャップが広がり人材の不足は （ア） に及ぶと言われている.
こうした人材不足を解消するべく,様々な方法で AI に理解のある人材育成が試みられている.そのような試みの一つとして,MOOCs は期待を寄せられている.著名な例としては,AI 研究の第一人者で,2014 年から 2017 年にかけて Baidu の AI 研究所所長を務めた （イ） が創業した Coursera などは入門から上級まで様々なレベルの AI 講義が開かれており,多くの受講者を惹きつけるに至っている.

1. Andrew Ng
1. LuCan
1. Yoshua Bengio
1. Ian Goodfellow

正解：1

-------

問176

以下の文章をよく読み,末尾の問に答えよ.

自動運転の実現に向けては,現行の法の枠組の中では公道での実験の可否や,事故が起きた際の責任の所在などの点で捉えづらい面がないかの解釈のすり合わせや,新たな法の策定などが求められている.

以下の自動運転走行許可の各国・各地域のスタンスに関する説明文として正しいものを選択肢から 1 つ選べ.

1. 英国では現行の法制度上では公道において自動運転の実証実験を行うのは法違反であるという見解が示されている
1. 米国ネバダ州では自動運転の走行や運転免許が許可制にて認められた
1. 日本国内では自動運転車の公道での走行は無制限に許可されている
1. 上記の選択肢の中に正しい選択肢は存在しない

正解：2
（AI白書：p.378-）

-------

問177

AI の活用が国の経済成長を牽引する柱の 1 つになるという共通認識から,先進国各国では国の経済成長戦略の一部に AI の研究開発戦略が盛り込まれるようになっている.

こうした各国とその国の経済成長戦略の組み合わせとして正しいものを 1 つ選べ.

1. 中国 - デジタル戦略 2025
1. ドイツ - RAS 2020 戦略
1. 英国 - インターネットプラス AI3 年行動実施法案
1. 日本 - 新産業構造ビジョン

正解：4

【解説】  
正しい組み合わせは以下の通り.
日本 - 新産業構造ビジョン
英国 - RAS 2020 戦略
ドイツ - デジタル戦略2025
中国 - インターネットプラスAI3年行動実施法案
（AI白書：p.394-）

-------

問178

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングでの学習を効率的に行うにあたって,共有データセットの整備が徐々に進められている.しかしながら,現在広く普及しているものには,いくつか問題点が指摘されている.
第一は, （ア） 問題である.現在は公正な利用がなされているとされているが,企業が共有データセットを利用して学習したモデルを自社のプロダクトに転用して売り上げを上げようとした場合問題はないのかという議論が巻き起こっている.
他問題として,これは日本にとって問題であるが,多くのデータセットが （イ） であることが挙げられる.これにより,日本固有の食べ物を認識しようとすると,それが全く別の国の食べ物としてのみ認識されるという不具合が生じるに至っている.

1. 著作権
1. 自然権
1. 管理権
1. 財産権

正解：1
（AI白書：p.144-p.145）

-------

問179

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングでの学習を効率的に行うにあたって,共有データセットの整備が徐々に進められている.しかしながら,現在広く普及しているものには,いくつか問題点が指摘されている.
第一は, （ア） 問題である.現在は公正な利用がなされているとされているが,企業が共有データセットを利用して学習したモデルを自社のプロダクトに転用して売り上げを上げようとした場合問題はないのかという議論が巻き起こっている.他問題として,これは日本にとって問題であるが,多くのデータセットが （イ） であることが挙げられる.これにより,日本固有の食べ物を認識しようとすると,それが全く別の国の食べ物としてのみ認識されるという不具合が生じるに至っている.

1. 利用料が高額すぎる
1. アクセスの手順が難しい
1. データ量不足
1. 欧米圏で作成されたデータセットである

正解：4
（AI白書：p.144-p.145）

-------

問180

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

高度な AI モデルを作成していく為には,こうした共有のデータセットの拡充を進めると共に,学習モデルの共有を進め,こうした公開共有されたモデルを基にして独自のデータセットを適用して調整をしながら新たに学習をさせる （ア） が実用上鍵となるのではないかと言われている.

1. 強化学習
1. 転移学習
1. 教師あり学習
1. ディープラーニング

正解：2
（AI白書：p.146-p.147）

-------

問181

ディープラーニングの利活用は各産業で進められているが,それが実際にディープラーニングによるブレイクスルーによってもたらされたものであるのかどうかの認識が曖昧な場合も少なくない.

選択肢のうち,ディープラーニングの産業への利活用事例として適切でないものを 1 つ選べ.

1. ある自動車タイヤメーカーは熟練技術者の熟達した技をディープラーニングで学ばせ,生産工程における自動化を図ろうとしている
1. インフラ産業において,機械設備の老朽化や故障,その他異常を重大な過失に至る前に検知し対策を示唆する為にディープラーニングの活用が行われている
1. チケットの転売を防ぐために,チケットを全て電子化し,転売がどのようなルートで行われたのかを捕捉できるようにする為にディープラーニングを利用したサービスが話題となっている
1. サイバーセキュリティ産業において,マルウェアを素早く検知して対策を打つ為のより効率の高いプログラムをディープラーニングを用いて作成しようとしている

正解：3

【解説】  
選択肢3はブロックチェーンがキーとなって成立したサービス群.
（AI白書：p.209-）

-------

問182

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

全ての欠損値が完全に生じている場合には,様々な手法を使ってこれに対処することができる.1 つは欠損があるサンプルをそのまま削除してしまう （ア） である.これは欠損に偏りがあった場合には,データ全体の傾向を大きく変えてしまうことになるので使用する際には欠損に特定の偏りがないかを確認して使用することが肝要である.
他の事例としては,欠損しているある特徴量と相関が強い他の特徴量が存在している場合は,（イ） という方法もある.

1. 回帰補完
1. リストワイズ法
1. 平均補完
1. ステップワイズ法

正解：2

-------

問183

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

全ての欠損値が完全に生じている場合には,様々な手法を使ってこれに対処することができる.1 つは欠損があるサンプルをそのまま削除してしまう （ア） である.これは欠損に偏りがあった場合には,データ全体の傾向を大きく変えてしまうことになるので使用する際には欠損に特定の偏りがないかを確認して使用することが肝要である.
他の事例としては,欠損しているある特徴量と相関が強い他の特徴量が存在している場合は,（イ） という方法もある.

1. 回帰補完
1. リストワイズ法
1. 平均補完
1. ステップワイズ法

正解：1

-------

問184

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

機械学習による分析を行う際,カテゴリーデータをそのまま扱うのは非常に難しい.このため,これを数値に変換して扱いやすくすることが一般的である.
ドリンクのサイズ S, M, L などの順序を持つ文字列のカテゴリーデータの場合,それぞれの値に対応する数値を辞書型データで用意し,これを数値に変化する方法 （ア） を利用して変換を行うことがある.
また順序を持たない名義特徴量のカテゴリーデータについては,各変数に対応したダミー変数を新たに作り出す （イ） が有用である.

1. ラッピング
1. マッピング
1. ワンホットエンコーディング
1. ダミーエンコーディング

正解：2

-------

問185

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

機械学習による分析を行う際,カテゴリーデータをそのまま扱うのは非常に難しい.このため,これを数値に変換して扱いやすくすることが一般的である.
ドリンクのサイズ S, M, L などの順序を持つ文字列のカテゴリーデータの場合,それぞれの値に対応する数値を辞書型データで用意し,これを数値に変化する方法 （ア） を利用して変換を行うことがある.
また順序を持たない名義特徴量のカテゴリーデータについては,各変数に対応したダミー変数を新たに作り出す （イ） が有用である.

1. ラッピング
1. マッピング
1. ワンホットエンコーディング
1. ダミーエンコーディング

正解：3

-------

問186

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

既存の学習済みニューラルネットワークモデルを活用する手法に（ア）と（イ）がある.（ア）では,学習済みモデルに対して新たに別の課題を学習させることで,少量のデータセットかつ少ない計算量で高い性能のモデルを得ることができる.また,（イ）は,学習済みの大規模モデルの入力と出力を小規模なモデルの教師データとして利用することで,少ない計算資源で従来のモデルと同程度の性能を実現することが可能となる.

1. 重み共有
1. 転移学習
1. 蒸留
1. ダウンサンプリング

正解：2

-------

問187

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

既存の学習済みニューラルネットワークモデルを活用する手法に（ア）と（イ）がある.（ア）では,学習済みモデルに対して新たに別の課題を学習させることで,少量のデータセットかつ少ない計算量で高い性能のモデルを得ることができる.また,（イ）は,学習済みの大規模モデルの入力と出力を小規模なモデルの教師データとして利用することで,少ない計算資源で従来のモデルと同程度の性能を実現することが可能となる.

1. 重み共有
1. 転移学習
1. 蒸留
1. ダウンサンプリング

正解：3

-------

問188

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

畳み込みニューラルネットワークの手法について扱う.（ア）は 1998 年に提案された,現在広く使われている CNN の元となるモデルであり,初めて多層 CNN に誤差逆伝播法を適用した手法である.2012 年に提案された（イ）は,画像認識のコンペティション ILSVRC で他手法に圧倒的な差をつけて優勝し,画像認識におけるディープラーニング活用の火付け役となった.しかし,一般に CNN は層を深くすると,パラメータ数が膨大となり学習が困難になってしまう傾向があった.層が深くなってもうまく学習を行うことができるモデルとして,ILSVRC2015 において多くの部門でトップの成績を収めた（ウ）がある.（ウ）は出力を入力と入力からの差分の和で表現したニューラルネットワークモデルである.

1. ResNet
1. VGGNet
1. LeNet
1. AlexNet

正解：3

-------

問189

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

畳み込みニューラルネットワークの手法について扱う.（ア）は 1998 年に提案された,現在広く使われている CNN の元となるモデルであり,初めて多層 CNN に誤差逆伝播法を適用した手法である.2012 年に提案された（イ）は,画像認識のコンペティション ILSVRC で他手法に圧倒的な差をつけて優勝し,画像認識におけるディープラーニング活用の火付け役となった.しかし,一般に CNN は層を深くすると,パラメータ数が膨大となり学習が困難になってしまう傾向があった.層が深くなってもうまく学習を行うことができるモデルとして,ILSVRC2015 において多くの部門でトップの成績を収めた（ウ）がある.（ウ）は出力を入力と入力からの差分の和で表現したニューラルネットワークモデルである.

1. ResNet
1. VGGNet
1. LeNet
1. AlexNet

正解：4

-------

問190

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

畳み込みニューラルネットワークの手法について扱う.（ア）は 1998 年に提案された,現在広く使われている CNN の元となるモデルであり,初めて多層 CNN に誤差逆伝播法を適用した手法である.2012 年に提案された（イ）は,画像認識のコンペティション ILSVRC で他手法に圧倒的な差をつけて優勝し,画像認識におけるディープラーニング活用の火付け役となった.しかし,一般に CNN は層を深くすると,パラメータ数が膨大となり学習が困難になってしまう傾向があった.層が深くなってもうまく学習を行うことができるモデルとして,ILSVRC2015 において多くの部門でトップの成績を収めた（ウ）がある.（ウ）は出力を入力と入力からの差分の和で表現したニューラルネットワークモデルである.

1. ResNet
1. VGGNet
1. LeNet
1. AlexNet

正解：1

-------

問191

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークで用いられる活性化関数について扱う.出力層の活性化関数には,回帰では（ア）が,多クラス分類では（イ）が一般的に利用されてきた.また中間層の活性化関数として,従来は（ウ）などが一般的に利用されてきた.しかし,これらの活性化関数を利用すると勾配消問題が起きやすいとい問題があったため,近年は,入力が 0 を超えていれば入力をそのまま出力に渡し,0 未満であれば出力を 0 とする（エ）や複数の線形関数の中での最大値を利用する（オ）などが利用されている.

1. ソフトマックス関数
1. 恒等関数
1. ステップ関数
1. 1~3 の選択肢に正解はない

正解：2

-------

問192

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークで用いられる活性化関数について扱う.出力層の活性化関数には,回帰では（ア）が,多クラス分類では（イ）が一般的に利用されてきた.また中間層の活性化関数として,従来は（ウ）などが一般的に利用されてきた.しかし,これらの活性化関数を利用すると勾配消問題が起きやすいとい問題があったため,近年は,入力が 0 を超えていれば入力をそのまま出力に渡し,0 未満であれば出力を 0 とする（エ）や複数の線形関数の中での最大値を利用する（オ）などが利用されている.

1. ソフトマックス関数
1. 恒等関数
1. ステップ関数
1. 1~3 の選択肢に正解はない

正解：1

-------

問193

（ウ）に当てはまらない選択肢を 1 つ選べ.

ニューラルネットワークで用いられる活性化関数について扱う.出力層の活性化関数には,回帰では（ア）が,多クラス分類では（イ）が一般的に利用されてきた.また中間層の活性化関数として,従来は（ウ）などが一般的に利用されてきた.しかし,これらの活性化関数を利用すると勾配消問題が起きやすいとい問題があったため,近年は,入力が 0 を超えていれば入力をそのまま出力に渡し,0 未満であれば出力を 0 とする（エ）や複数の線形関数の中での最大値を利用する（オ）などが利用されている.

1. 双曲線正接関数
1. 双曲線余弦関数
1. シグモイド関数
1. 1~3 の選択肢は全て当てはまる

正解：2

-------

問194

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークで用いられる活性化関数について扱う.出力層の活性化関数には,回帰では（ア）が,多クラス分類では（イ）が一般的に利用されてきた.また中間層の活性化関数として,従来は（ウ）などが一般的に利用されてきた.しかし,これらの活性化関数を利用すると勾配消問題が起きやすいとい問題があったため,近年は,入力が 0 を超えていれば入力をそのまま出力に渡し,0 未満であれば出力を 0 とする（エ）や複数の線形関数の中での最大値を利用する（オ）などが利用されている.

1. 動経基底関数
1. ソフトマックス関数
1. Maxout
1. ステップ関数

正解：5

-------

問195

（オ）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークで用いられる活性化関数について扱う.出力層の活性化関数には,回帰では（ア）が,多クラス分類では（イ）が一般的に利用されてきた.また中間層の活性化関数として,従来は（ウ）などが一般的に利用されてきた.しかし,これらの活性化関数を利用すると勾配消問題が起きやすいとい問題があったため,近年は,入力が 0 を超えていれば入力をそのまま出力に渡し,0 未満であれば出力を 0 とする（エ）や複数の線形関数の中での最大値を利用する（オ）などが利用されている.

1. 動経基底関数
1. ソフトマックス関数
1. Maxout
1. ステップ関数

正解：3

-------

問196

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

正則化とは,機械学習の学習において汎化誤差をできるだけ小さくするための手法の総称である.ディープニューラルネットワーク（DNN）の学習で一般に用いられる正則化の手法に（ア）があり,誤差関数に重みの L2 ノルムを加えることで重みの発散を抑えることができる.また,L2 ノルムの代わりに L1 ノルムを用いる L1正則化は,（イ）の一種であり,重要でないパラメータを 0 に近づけることができる. L1 正則化を回帰に利用した場合,（ウ）と呼ばれる.

1. 荷重減衰
1. ドロップアウト
1. 重み共有
1. 事前学習

正解：1

-------

問197

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

正則化とは,機械学習の学習において汎化誤差をできるだけ小さくするための手法の総称である.ディープニューラルネットワーク（DNN）の学習で一般に用いられる正則化の手法に（ア）があり,誤差関数に重みの L2 ノルムを加えることで重みの発散を抑えることができる.また,L2 ノルムの代わりに L1 ノルムを用いる L1正則化は,（イ）の一種であり,重要でないパラメータを 0 に近づけることができる. L1 正則化を回帰に利用した場合,（ウ）と呼ばれる.

1. オンライン学習
1. スパース正則化
1. チコノフ正則化
1. ミニバッチ学習

正解：2

-------

問198

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

正則化とは,機械学習の学習において汎化誤差をできるだけ小さくするための手法の総称である.ディープニューラルネットワーク（DNN）の学習で一般に用いられる正則化の手法に（ア）があり,誤差関数に重みの L2 ノルムを加えることで重みの発散を抑えることができる.また,L2 ノルムの代わりに L1 ノルムを用いる L1正則化は,（イ）の一種であり,重要でないパラメータを 0 に近づけることができる. L1 正則化を回帰に利用した場合,（ウ）と呼ばれる.

1. 線形回帰
1. ロジスティック回帰
1. Lasso回帰
1. Ridge回帰

正解：3

-------

問199

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングの実験に用いられるデータセットについて扱う.（ア）はアメリカの国立標準技術研究所によって提供されている手書き数字のデータベースである.また,スタンフォード大学がインターネット上から画像を集めて分類したデータセットである（イ）は,約 1400 万枚の自然画像を有しており,画像認識の様々なタスクに利用される.

1. CIFAR-10
1. Youtube-8M
1. MNIST
1. ImageNet

正解：3

-------

問200

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

ディープラーニングの実験に用いられるデータセットについて扱う.（ア）はアメリカの国立標準技術研究所によって提供されている手書き数字のデータベースである.また,スタンフォード大学がインターネット上から画像を集めて分類したデータセットである（イ）は,約 1400 万枚の自然画像を有しており,画像認識の様々なタスクに利用される.

1. CIFAR-10
1. Youtube-8M
1. NIST
1. ImageNet

正解：4

-------

問201

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

機械学習の手法は学習の枠組みに応じて主に三つに分類することができる.
（ア）は入力とそれに対する出力のペアの集合を学習用データとする手法で,（イ）などが（ア）に含まれる.（ウ）は入力の集合だけから学習を行う手法であり,（エ）などが（ウ）に含まれる.最後に（オ）は,最終結果または連続した行動の結果に対して報酬を与え,報酬ができるだけ大きくなるような行動を探索する手法である.

1. 教師あり学習
1. 教師なし学習
1. 強化学習
1. ディープラーニング

正解：1

-------

問202

（イ）に当てはまらない選択肢を 1 つ選べ.

機械学習の手法は学習の枠組みに応じて主に三つに分類することができる.
（ア）は入力とそれに対する出力のペアの集合を学習用データとする手法で,（イ）などが（ア）に含まれる.（ウ）は入力の集合だけから学習を行う手法であり,（エ）などが（ウ）に含まれる.最後に（オ）は,最終結果または連続した行動の結果に対して報酬を与え,報酬ができるだけ大きくなるような行動を探索する手法である.

1. サポートベクターマシン
1. k平均法
1. ロジスティック回帰
1. 決定木

正解：2

-------

問203

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

機械学習の手法は学習の枠組みに応じて主に三つに分類することができる.
（ア）は入力とそれに対する出力のペアの集合を学習用データとする手法で,（イ）などが（ア）に含まれる.（ウ）は入力の集合だけから学習を行う手法であり,（エ）などが（ウ）に含まれる.最後に（オ）は,最終結果または連続した行動の結果に対して報酬を与え,報酬ができるだけ大きくなるような行動を探索する手法である.

1. 教師あり学習
1. 教師なし学習
1. 強化学習
1. ディープラーニング

正解：2

-------

問204

（エ）に当てはまらない選択肢を 1 つ選べ.

機械学習の手法は学習の枠組みに応じて主に三つに分類することができる.
（ア）は入力とそれに対する出力のペアの集合を学習用データとする手法で,（イ）などが（ア）に含まれる.（ウ）は入力の集合だけから学習を行う手法であり,（エ）などが（ウ）に含まれる.最後に（オ）は,最終結果または連続した行動の結果に対して報酬を与え,報酬ができるだけ大きくなるような行動を探索する手法である.

1. 主成分分析（PCA）
1. 独立成分分析
1. 自己符号化器
1. k近傍法

正解：4

-------

問205

（オ）に最もよくあてはまる選択肢を 1 つ選べ.

機械学習の手法は学習の枠組みに応じて主に三つに分類することができる.
（ア）は入力とそれに対する出力のペアの集合を学習用データとする手法で,（イ）などが（ア）に含まれる.（ウ）は入力の集合だけから学習を行う手法であり,（エ）などが（ウ）に含まれる.最後に（オ）は,最終結果または連続した行動の結果に対して報酬を与え,報酬ができるだけ大きくなるような行動を探索する手法である.

1. 教師あり学習
1. 教師なし学習
1. 半教師あり学習
1. 強化学習

正解：4

-------

問206

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

機械学習の種類を大きく分類すると教師あり学習,教師なし学習,強化学習がある.ニューラルネットワークにもそれらに対応するものがある.例えば,教師あり学習には（ア）,教師なし学習には（イ）,強化学習には（ウ）などがある.

1. DQN
1. VGG16
1. Auto Encoder

正解：2

-------

問207

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

機械学習の種類を大きく分類すると教師あり学習,教師なし学習,強化学習がある.ニューラルネットワークにもそれらに対応するものがある.例えば,教師あり学習には（ア）,教師なし学習には（イ）,強化学習には（ウ）などがある.

1. DQN
1. VGG16
1. Auto Encoder

正解：3

-------

問208

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

機械学習の種類を大きく分類すると教師あり学習,教師なし学習,強化学習がある.ニューラルネットワークにもそれらに対応するものがある.例えば,教師あり学習には（ア）,教師なし学習には（イ）,強化学習には（ウ）などがある.

1. DQN
1. VGG16
1. Auto Encoder

正解：1

-------

問209

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

畳み込みニューラルネットワークに特有の構造として,畳み込み層とプーリング層がある.これらは画像から特徴量を抽出するために用いられる.逆に特徴量（特徴マップ）から画像を生成する際には,それらと逆の操作を行う.代表的な構造として,畳込み層の逆操作である（ア）やプーリングの逆操作である（イ）がある.これらの構造を用いるタスクの例として（ウ）がある.

1. ドロップアウト層
1. 逆プーリング層
1. 逆畳み込み層
1. アンプーリング層

正解：3

-------

問210

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

畳み込みニューラルネットワークに特有の構造として,畳み込み層とプーリング層がある.これらは画像から特徴量を抽出するために用いられる.逆に特徴量（特徴マップ）から画像を生成する際には,それらと逆の操作を行う.代表的な構造として,畳込み層の逆操作である（ア）やプーリングの逆操作である（イ）がある.これらの構造を用いるタスクの例として（ウ）がある.

1. ドロップアウト層
1. 逆プーリング層
1. 逆畳み込み層
1. アンプーリング層

正解：4

-------

問211

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

畳み込みニューラルネットワークに特有の構造として,畳み込み層とプーリング層がある.これらは画像から特徴量を抽出するために用いられる.逆に特徴量（特徴マップ）から画像を生成する際には,それらと逆の操作を行う.代表的な構造として,畳込み層の逆操作である（ア）やプーリングの逆操作である（イ）がある.これらの構造を用いるタスクの例として（ウ）がある.

1. 画像セグメンテーション
1. 画像認識
1. 物体追跡
1. 物体検知

正解：1

-------

問212

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークの学習は,損失関数（コスト関数）の最適化により行われる.そして,その損失関数は学習の目的に応じて決定する.よく使われる損失関数として,回問題には（ア）,分問題には（イ）がある.また分布を直接学習する際には（ウ）が用いられることもある.さらに,損失関数にパラメータの二乗ノルムを加えると（エ）となる.

1. ステップ関数
1. 平均二乗誤差関数
1. KL ダイバージェンス
1. 交差エントロピー誤差関数

正解：2

-------

問213

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークの学習は,損失関数（コスト関数）の最適化により行われる.そして,その損失関数は学習の目的に応じて決定する.よく使われる損失関数として,回問題には（ア）,分問題には（イ）がある.また分布を直接学習する際には（ウ）が用いられることもある.さらに,損失関数にパラメータの二乗ノルムを加えると（エ）となる.

1. ステップ関数
1. 平均二乗誤差関数
1. KL ダイバージェンス
1. 交差エントロピー誤差関数

正解：4

-------

問214

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークの学習は,損失関数（コスト関数）の最適化により行われる.そして,その損失関数は学習の目的に応じて決定する.よく使われる損失関数として,回問題には（ア）,分問題には（イ）がある.また分布を直接学習する際には（ウ）が用いられることもある.さらに,損失関数にパラメータの二乗ノルムを加えると（エ）となる.

1. ステップ関数
1. 平均二乗誤差関数
1. KL ダイバージェンス
1. 交差エントロピー誤差関数

正解：3

-------

問215

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークの学習は,損失関数（コスト関数）の最適化により行われる.そして,その損失関数は学習の目的に応じて決定する.よく使われる損失関数として,回問題には（ア）,分問題には（イ）がある.また分布を直接学習する際には（ウ）が用いられることもある.さらに,損失関数にパラメータの二乗ノルムを加えると（エ）となる.

1. L2 正則化
1. ドロップアウト
1. バッチ正規化
1. アーリーストッピング

正解：1

-------

問216

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークには様々なモデルがあり,タスクによって適切な選択をする必要がある.例えば,画像を扱う際には（ア）,自然言語処理などの系列データには（イ）がよく使われる.他にも次元削減には（ウ）,画像生成には（エ）などが用いられる.

1. RNN
1. CNN
1. GAN
1. Auto Encoder

正解：2

-------

問217

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークには様々なモデルがあり,タスクによって適切な選択をする必要がある.例えば,画像を扱う際には（ア）,自然言語処理などの系列データには（イ）がよく使われる.他にも次元削減には（ウ）,画像生成には（エ）などが用いられる.

1. RNN
1. CNN
1. GAN
1. Auto Encoder

正解：1

-------

問218

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークには様々なモデルがあり,タスクによって適切な選択をする必要がある.例えば,画像を扱う際には（ア）,自然言語処理などの系列データには（イ）がよく使われる.他にも次元削減には（ウ）,画像生成には（エ）などが用いられる.

1. RNN
1. CNN
1. GAN
1. Auto Encoder

正解：4

-------

問219

（エ）に最もよくあてはまる選択肢を 1 つ選べ.

ニューラルネットワークには様々なモデルがあり,タスクによって適切な選択をする必要がある.例えば,画像を扱う際には（ア）,自然言語処理などの系列データには（イ）がよく使われる.他にも次元削減には（ウ）,画像生成には（エ）などが用いられる.

1. RNN
1. CNN
1. GAN
1. Auto Encoder

正解：3

-------

問220

ニューラルネットワークの学習には勾配降下法が用いられる.勾配降下法の手順を適切な順番に並べ替えたとき,正しい順番になるものを選択肢から 1 つ選べ.

A．重みとバイアスを初期化する.
B．誤差を減らすように重み（バイアス）を修正する.
C．最適な重みやバイアスになるまで繰り返す.
D．ネットワークの出力と正解ラベルとの誤差を計算する.
E．データ（ミニバッチ）をネットワークに入力し出力を得る.

1. A.E.D.B.C
1. A.C.D.B.E
1. C.D.A.E.B
1. E.C.B.A.D
5.B.D.E.C.A

正解：1

-------

問221

ニューラルネットワークの学習には勾配降下法が用いられる.勾配降下法の手順を適切な順番に並べ替えたとき,2番目になるのはどれか.

A．重みとバイアスを初期化する.
B．誤差を減らすように重み（バイアス）を修正する.
C．最適な重みやバイアスになるまで繰り返す.
D．ネットワークの出力と正解ラベルとの誤差を計算する.
E．データ（ミニバッチ）をネットワークに入力し出力を得る.

1. A
1. B
1. C
1. D
5.E

正解：5

-------

問222

ニューラルネットワークの学習には勾配降下法が用いられる.勾配降下法の手順を適切な順番に並べ替えたとき,3番目になるのはどれか.

A．重みとバイアスを初期化する.
B．誤差を減らすように重み（バイアス）を修正する.
C．最適な重みやバイアスになるまで繰り返す.
D．ネットワークの出力と正解ラベルとの誤差を計算する.
E．データ（ミニバッチ）をネットワークに入力し出力を得る.

1. A
1. B
1. C
1. D
5.E

正解：4

-------

問223

ニューラルネットワークの学習には勾配降下法が用いられる.勾配降下法の手順を適切な順番に並べ替えたとき,4番目になるのはどれか.

A．重みとバイアスを初期化する.
B．誤差を減らすように重み（バイアス）を修正する.
C．最適な重みやバイアスになるまで繰り返す.
D．ネットワークの出力と正解ラベルとの誤差を計算する.
E．データ（ミニバッチ）をネットワークに入力し出力を得る.

1. A
1. B
1. C
1. D
5.E

正解：2

-------

問224

ニューラルネットワークの学習には勾配降下法が用いられる.勾配降下法の手順を適切な順番に並べ替えたとき,5番目になるのはどれか.

A．重みとバイアスを初期化する.
B．誤差を減らすように重み（バイアス）を修正する.
C．最適な重みやバイアスになるまで繰り返す.
D．ネットワークの出力と正解ラベルとの誤差を計算する.
E．データ（ミニバッチ）をネットワークに入力し出力を得る.

1. A
1. B
1. C
1. D
5.E

正解：3

-------

問225

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

画像認識のモデルとしてResNet がある.これは求めたい関数と入力との差である（ア）を学習するようにしたことで深いネットワークの学習を容易にした.

1. 誤差
1. 恒等写像
1. 勾配
1. 残差

正解：4

-------

問226

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

AI 研究の進展に伴い,実業家（ア）が提唱したシンギュラリティ（イ） という概念は議論を呼び,これが近い未来に到来するのか否かという議論が巻き起こり,様々な有識者の間でも大きく主張が分かれている.

1. ライ・カーツワイル
1. レイ・カーツワイル
1. ルイ・カーツワイル
1. レイ・チャールズ

正解：2

-------

問227

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

AI 研究の進展に伴い,実業家（ア）が提唱したシンギュラリティ（イ）という概念は議論を呼び,これが近い未来に到来するのか否かという議論が巻き起こり,様々な有識者の間でも大きく主張が分かれている.

1. 指数的特異点
1. 分子的特異点
1. 空間的特異点
1. 技術的特異点

正解：4

-------

問228

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

自然言語処理の研究においても,ディープラーニングを利用した研究が目立ちつつあるが,その成果は分野においてまちまちである.
例えば,機械翻訳 や（ア）おいては大幅な性能向上が見られる一方で,構文解析や（イ） のように連続的な精度向上は見られるものの基本的な手法は大きく変わらないもの,そして 文脈解析 や（ウ）など現在のアプローチでは実用的な精度は見込めないものなどがある.

1. 常識推論
1. 画像説明文生成
1. 新言語生成
1. 意味解析

正解：2
（AI白書：p.52-p.58, p.215-p.219, p.222-p.223）

-------

問229

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

自然言語処理の研究においても,ディープラーニングを利用した研究が目立ちつつあるが,その成果は分野においてまちまちである.
例えば,機械翻訳 や（ア）おいては大幅な性能向上が見られる一方で,構文解析や（イ） のように連続的な精度向上は見られるものの基本的な手法は大きく変わらないもの,そして 文脈解析 や（ウ）など現在のアプローチでは実用的な精度は見込めないものなどがある.

1. 常識推論
1. 画像説明文生成
1. 新言語生成
1. 意味解析

正解：4
（AI白書：p.52-p.58, p.215-p.219, p.222-p.223）

-------

問230

（ウ）に最もよくあてはまる選択肢を 1 つ選べ.

自然言語処理の研究においても,ディープラーニングを利用した研究が目立ちつつあるが,その成果は分野においてまちまちである.
例えば,機械翻訳 や（ア）おいては大幅な性能向上が見られる一方で,構文解析や（イ） のように連続的な精度向上は見られるものの基本的な手法は大きく変わらないもの,そして 文脈解析 や（ウ）など現在のアプローチでは実用的な精度は見込めないものなどがある.

1. 常識推論
1. 画像説明文生成
1. 新言語生成
1. 意味解析

正解：1
（AI白書：p.52-p.58, p.215-p.219, p.222-p.223）

-------

問231

（ア）に最もよくあてはまる選択肢を 1 つ選べ.

AI が実世界における抽象概念を理解し,知識処理を行う上では,（ア） を通じた高レベルの身体知を獲得し,次に （イ）を通じて言語の意味理解を促し,抽象概念・知識処理へと至るのではないかということが議論されている.

1. 身体性
1. 帯域性
1. 情報性
1. 領域性

正解：1
（AI白書：p.46-p.48, p.74-）

-------

問232

（イ）に最もよくあてはまる選択肢を 1 つ選べ.

AI が実世界における抽象概念を理解し,知識処理を行う上では,（ア） を通じた高レベルの身体知を獲得し,次に （イ）を通じて言語の意味理解を促し,抽象概念・知識処理へと至るのではないかということが議論されている.

1. 全体知
1. 情報知
1. 身体知
1. 領域知

正解：3
（AI白書：p.46-p.48, p.74-）

-------

問233

次の説明について,最も関連する事象を選択肢の中から 1 つ選べ.

層を沢山重ねた深い層であってもうまく学習ができるように出力を入力と入力からの差分の和としてモデリングしたネットワークの枠組み ResNet が提案され高い精度の識別性能を誇っている.

1. クラス分類
1. 物体検出
1. 物体セグメンテーション
1. 画像キャプション生成
5.画像生成

正解：1

-------

問234

次の説明について,最も関連する事象を選択肢の中から 1 つ選べ.
画像内に含まれるとある物体を取り囲むようなボックスを推定するタスクを行うもの.

1. クラス分類
1. 物体検出
1. 物体セグメンテーション
1. 画像キャプション生成
5.画像生成

正解：2
（AI白書：p.40-p.41）

-------

問235

次の説明について,最も関連する事象を選択肢の中から 1 つ選べ.
対象とする物体とその周囲の背景を境界まで切り分けるようなタスクを行うもの.

1. クラス分類
1. 物体検出
1. 物体セグメンテーション
1. 画像キャプション生成
5.画像生成

正解：3
（AI白書：p.40-p.41）

-------

問236

次の説明について,最も関連する事象を選択肢の中から 1 つ選べ.
画像内に表示されている女性を認識し,「青い服を着てスマートフォンをいじっている」などのようにその対象が何をしているかを表示させることができるようになりつつある.

1. クラス分類
1. 物体検出
1. 物体セグメンテーション
1. 画像キャプション生成
5.画像生成

正解：4
（AI白書：p.40-p.41）

-------

問237

次の説明について,最も関連する事象を選択肢の中から 1 つ選べ.
2015 年に google 社が通常の画像をまるで夢に出てくるかのような不思議な画像に変換して表示する Deep Dream というプログラムを発表し話題を呼んだ.

1. クラス分類
1. 物体検出
1. 物体セグメンテーション
1. 画像キャプション生成
5.画像生成

正解：5
（AI白書：p.192-p.195）

-------

問238

次の説明について,最も関連する事象を選択肢の中から 1 つ選べ.

音声を認識したい対象とそれ以外の雑音に分離する.

1. End to End 音声認識
1. End to Start の音声認識
1. 音素状態認識
1. 雑音・残響抑圧

正解：4

-------

問239

次の説明について,最も関連する事象を選択肢の中から 1 つ選べ.

音声の周波数スペクトル,すなわち音響特徴量をインプットとして,音素状態のカテゴリに分類する.

1. End to End 音声認識
1. End to Start の音声認識
1. 音素状態認識
1. 雑音・残響抑圧

正解：3

-------

問240

次の説明について,最も関連する事象を選択肢の中から 1 つ選べ.

音響特徴量から音素,音素から文字列,文字列から単語列に直接変換して言語モデルを学習するアプローチ.

1．End to End 音声認識
2．End to Start の音声認識
3．音素状態認識
4．雑音・残響抑圧

正解：1
